[
["day-0.html", "4 MIDFIELD Pre-Institute Workshop 4.1 R basics 4.2 Graph basics 4.3 Data basics", " 4 MIDFIELD Pre-Institute Workshop Agenda [link] This is an optional session designed for R novices. If you cannot attend this session on Sunday, you are welcome to work these tutorials on your own before the Monday/Tuesday sessions. The tutorials give the R novice a quick introduction to three essential elements of data science using R: R basics Graph basics Data basics The tutorials are designed to be completed by an R novice in less than 50 minutes each. The timing has been student-tested, but of course your mileage may vary. ▲ top of page 4.1 R basics An introduction to R adapted from (Healy, 2019a) with extra material from (Matloff, 2019). If you already have R experience, you might still want to browse this section in case you find something new. If the prerequisites have been met, the tutorial should take no longer than 50 minutes. 4.1.1 Prerequisites Every tutorial assumes that You completed the Getting started instructions You launched midfield_institute.Rproj to start the R session One of the packages is available only on GitHub. To install it, type in the Console, devtools::install_github(&quot;kjhealy/socviz&quot;) Note on usage: The double-colon notation package::name accesses a function from a specific package. In this case, for example, we are accessing the install_github() function from the devtools package. Use File &gt; New File &gt; R Script to create a new R script Name the script 01-R-basics.R Save it in the scripts directory Add a minimal header at the top of the script (if you wish) Use library() to load the packages we will use # workshop R basics # name # date library(&quot;tidyverse&quot;) library(&quot;socviz&quot;) Run the script by clicking the Source button. If you see an error like this one, Error in library(&quot;pkg_name&quot;) : there is no package called &#39;pkg_name&#39; then you should install the missing package(s) and run the script again. [To review how to install an R package] Guidelines As you work through the tutorial, type a line or chunk of code then File &gt; Save and Source. Confirm that your result matches the tutorial result. Your turn exercises give you chance to devise your own examples and check them out. You learn by doing (but you knew that already)! 4.1.2 Everything in R has a name In R, every object has a name. named entities, like x or y data you have loaded, like my_data functions you use, like sin() Some names are forbidden reserved words, like TRUE or FALSE programming words, like Inf, for, else, and function special entities, like NA and NaN Some names should not be used because they name commonly used functions q() quit c() combine or concatenate mean() range() var() variance Names in R are case-sensitive my_data and My_Data are different objects I follow the style guide used in the tidyverse by naming things in lower case, with words separated by underscores, and no spaces If you want to know if a name has already been used in a package you have loaded, go to the RStudio console, type a question mark followed by the name, e.g., ? c() ? mean() If the name is in use, a help page appears in the RStudio Help pane. 4.1.3 Everything in R is an object Origins of R objects Some objects are built in to R Some objects are loaded with packages Some objects are created by you Type this line of code in your script, Save, Source. c() is the function to combine or concatenate its elements to create a vector. c(1, 2, 3, 1, 3, 25) In these notes, everything that comes back to us in the Console as the result of running a script is shown prefaced by #&gt;. For example, after running your script, the Console should show, #&gt; [1] 1 2 3 1 3 25 But what is that [1] here? It’s just a row label. We’ll go into that later, not needed yet. We can assign the vector to a name. x &lt;- c(1, 2, 3, 1, 3, 25) y &lt;- c(5, 31, 71, 1, 3, 21, 6) To see the result in the Console, type the object name in the script, Save, and Source. (Remember, type the line of code but not the line prefaced by #&gt;—that’s the output line so you can check your results.) x #&gt; [1] 1 2 3 1 3 25 y #&gt; [1] 5 31 71 1 3 21 6 You create objects my assigning them names &lt;- is the assignment operator (keyboard shortcut: ALT –) objects exist in your R project workspace, listed in the RStudio Environment pane Datasets are also named objects, and a large number of datasets are included in the base R installation. For example,LakeHuron contains annual measurements of the lake level, in feet, from 1875–1972. LakeHuron #&gt; Time Series: #&gt; Start = 1875 #&gt; End = 1972 #&gt; Frequency = 1 #&gt; [1] 580.38 581.86 580.97 580.80 579.79 580.39 580.42 580.82 581.40 581.32 #&gt; [11] 581.44 581.68 581.17 580.53 580.01 579.91 579.14 579.16 579.55 579.67 #&gt; [21] 578.44 578.24 579.10 579.09 579.35 578.82 579.32 579.01 579.00 579.80 #&gt; [31] 579.83 579.72 579.89 580.01 579.37 578.69 578.19 578.67 579.55 578.92 #&gt; [41] 578.09 579.37 580.13 580.14 579.51 579.24 578.66 578.86 578.05 577.79 #&gt; [51] 576.75 576.75 577.82 578.64 580.58 579.48 577.38 576.90 576.94 576.24 #&gt; [61] 576.84 576.85 576.90 577.79 578.18 577.51 577.23 578.42 579.61 579.05 #&gt; [71] 579.26 579.22 579.38 579.10 577.95 578.12 579.75 580.85 580.41 579.96 #&gt; [81] 579.61 578.76 578.18 577.21 577.13 579.10 578.25 577.91 576.89 575.96 #&gt; [91] 576.80 577.68 578.38 578.52 579.74 579.31 579.89 579.96 Now you can see how the row labels work. There are 10 numbers per row, here, so the second row starts with the 11th, indicated by [11]. The last row starts with the 91st value [91] and ends with the 98th value. In the Console, type ? LakeHuron to see the help page for the data set Individual elements of a vector are obtained using [] notation. For example, the first five lake level readings are extracted with LakeHuron[1:5] #&gt; [1] 580.38 581.86 580.97 580.80 579.79 The 4th element alone, LakeHuron[4] #&gt; [1] 580.8 4.1.4 Do things in R using functions Functions do something useful functions are objects the perform actions for you functions produce output based on the input it receives functions are recognized by the parentheses at the end of their names The parentheses are where we include the inputs (arguments) to the function c() concatenates the comma-separated numbers in the parentheses to create a vector mean() computes the mean of a vector of numbers sd() computes the standard deviation of a vector of numbers summary() returns a summary of the object If we try mean() with no inputs, we get an error statement mean() #&gt; Error in mean.default() : argument &quot;x&quot; is missing, with no default If we use the Lake Huron dataset as the argument, the function is computed and displayed. Add these lines to your script, Save, and Source. mean(LakeHuron) #&gt; [1] 579.0041 sd(LakeHuron) #&gt; [1] 1.318299 summary(LakeHuron) #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. #&gt; 576.0 578.1 579.1 579.0 579.9 581.9 We can extract subsets of data using functions. For example, If we wanted only the first five even-numbered elements, we use c() to create a vector of indices to the desired elements, LakeHuron[c(2, 4, 6, 8, 10)] #&gt; [1] 581.86 580.80 580.39 580.82 581.32 If we wanted every 5th entry over the full data set, we use length() to determine how many entries there are, and the sequence function seq() to create the vector of indices, n &lt;- length(LakeHuron) LakeHuron[seq(from = 5, to = n, by = 5)] #&gt; [1] 579.79 581.32 580.01 579.67 579.35 579.80 579.37 578.92 579.51 577.79 #&gt; [11] 580.58 576.24 578.18 579.05 577.95 579.96 577.13 575.96 579.74 Because we will be using the ggplot2 package for graphics, we will not be using the base R plot() function very often, but it is useful for a quick look at data. Add these lines to your script, Save, and Source. plot(LakeHuron) The help pages for functions are quickly accessed via the Console. In the Console type one line at a time and Enter to see the function help page. ? mean() ? sd() ? summary() 4.1.5 R functions come in packages Functions are bundled in packages Families of useful functions are bundled into packages that you can install, load, and use Packages allow you to build on the work of others You can write your own functions and packages too A lot of the work in data science consists of choosing the right functions and giving them the right arguments to get our data into the form we need for analysis or visualization Functions operate on the input you provide and give you back a result. Type the following in your script, Save, and Source. table(x) # table of counts #&gt; x #&gt; 1 2 3 25 #&gt; 2 1 2 1 sd(y) # standard deviation #&gt; [1] 25.14435 x * 5 # multiply every element by a scalar #&gt; [1] 5 10 15 5 15 125 y + 1 # add a scalar to every element #&gt; [1] 6 32 72 2 4 22 7 x + x # add elements #&gt; [1] 2 4 6 2 6 50 Comments are annotations to make the source code easier for humans to understand but are ignored by R. Comments in R are denoted by a hashtag #. 4.1.6 R objects have class Everything is an object and every object has a class. class(x) #&gt; [1] &quot;numeric&quot; class(summary) #&gt; [1] &quot;function&quot; Certain actions will change the class of an object. Suppose we try create a vector from the x object and a text string, new_vector &lt;- c(x, &quot;Apple&quot;) new_vector #&gt; [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;1&quot; &quot;3&quot; &quot;25&quot; &quot;Apple&quot; class(new_vector) #&gt; [1] &quot;character&quot; By adding the word “Apple” to the vector, R changed the class from “numeric” to “character”. All the numbers are enclosed in quotes: they are now character strings and cannot be used in calculations. The most common class of data object we will use is the data frame. titanic # data in the socviz package #&gt; fate sex n percent #&gt; 1 perished male 1364 62.0 #&gt; 2 perished female 126 5.7 #&gt; 3 survived male 367 16.7 #&gt; 4 survived female 344 15.6 class(titanic) #&gt; [1] &quot;data.frame&quot; You can see there are four variables: fate, sex, n, percent. Two variables (columns) are numeric, two are categorical. You can pick variable out of a data frame using the $ operator, titanic$percent #&gt; [1] 62.0 5.7 16.7 15.6 From the tidyverse, we will regularly use a augmented data frame called a tibble. We can convert the titanic data frame to a tibble using as_tibble(). titanic_tb &lt;- as_tibble(titanic) class(titanic_tb) #&gt; [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; titanic_tb #&gt; # A tibble: 4 x 4 #&gt; fate sex n percent #&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 perished male 1364 62 #&gt; 2 perished female 126 5.7 #&gt; 3 survived male 367 16.7 #&gt; 4 survived female 344 15.6 The tibble includes additional information about the variables 4.1.7 R objects have structure To see inside an object ask for its structure using the str() function. str(x) #&gt; num [1:6] 1 2 3 1 3 25 str(titanic) #&gt; &#39;data.frame&#39;: 4 obs. of 4 variables: #&gt; $ fate : Factor w/ 2 levels &quot;perished&quot;,&quot;survived&quot;: 1 1 2 2 #&gt; $ sex : Factor w/ 2 levels &quot;female&quot;,&quot;male&quot;: 2 1 2 1 #&gt; $ n : num 1364 126 367 344 #&gt; $ percent: num 62 5.7 16.7 15.6 str(titanic_tb) #&gt; Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 4 obs. of 4 variables: #&gt; $ fate : Factor w/ 2 levels &quot;perished&quot;,&quot;survived&quot;: 1 1 2 2 #&gt; $ sex : Factor w/ 2 levels &quot;female&quot;,&quot;male&quot;: 2 1 2 1 #&gt; $ n : num 1364 126 367 344 #&gt; $ percent: num 62 5.7 16.7 15.6 I also like to use the glimpse() function from the tidyverse. glimpse(x) #&gt; num [1:6] 1 2 3 1 3 25 glimpse(titanic) #&gt; Observations: 4 #&gt; Variables: 4 #&gt; $ fate &lt;fct&gt; perished, perished, survived, survived #&gt; $ sex &lt;fct&gt; male, female, male, female #&gt; $ n &lt;dbl&gt; 1364, 126, 367, 344 #&gt; $ percent &lt;dbl&gt; 62.0, 5.7, 16.7, 15.6 glimpse(titanic_tb) #&gt; Observations: 4 #&gt; Variables: 4 #&gt; $ fate &lt;fct&gt; perished, perished, survived, survived #&gt; $ sex &lt;fct&gt; male, female, male, female #&gt; $ n &lt;dbl&gt; 1364, 126, 367, 344 #&gt; $ percent &lt;dbl&gt; 62.0, 5.7, 16.7, 15.6 4.1.8 R does what you tell it Expect to make errors and don’t worry when that happens. You won’t break anything. Healy (2019b) offers this advice for three specific things to watch out for: Make sure parentheses are balanced—that every opening ( has a corresponding closing ). Make sure you complete your expressions. If you see a + in the Console instead of the usual prompt &gt;, that means that R thinks you haven’t written a complete expression. You can hit Esc or Ctrl C to force your way back to the Console and try correcting the code. In ggplot specifically, as you will see, we create plots layer by layer, using a + character at the end of the line—not at the beginning of the next line. For example, you would write this, ggplot(data = mpg, aes(x = displ, y = hwy)) + geom_point() not this, # error caused by incorrectly placed + ggplot(data = mpg, aes(x = displ, y = hwy)) + geom_point() To conclude, let’s make bar graph of the titanic data, ggplot(data = titanic_tb, mapping = aes(x = sex, y = n, fill = fate)) + geom_col() + coord_flip() Your turn. As shown, color distinguishes those who survived from those who did not and bar length gives totals by sex. Make a small change so that color denotes sex and bar length gives totals of survived and perished. 4.1.9 Pipe operator %&gt;% is the pipe operator from the magrittr package, part of the tidyverse suite of packages. The pipe takes the output of one statement and makes it the input of the next statement. You can think of it as the word “then”. In this example, we’ll use the starwars dataset from the dplyr package, glimpse(starwars) #&gt; Observations: 87 #&gt; Variables: 13 #&gt; $ name &lt;chr&gt; &quot;Luke Skywalker&quot;, &quot;C-3PO&quot;, &quot;R2-D2&quot;, &quot;Darth Vader&quot;, ... #&gt; $ height &lt;int&gt; 172, 167, 96, 202, 150, 178, 165, 97, 183, 182, 188... #&gt; $ mass &lt;dbl&gt; 77.0, 75.0, 32.0, 136.0, 49.0, 120.0, 75.0, 32.0, 8... #&gt; $ hair_color &lt;chr&gt; &quot;blond&quot;, NA, NA, &quot;none&quot;, &quot;brown&quot;, &quot;brown, grey&quot;, &quot;b... #&gt; $ skin_color &lt;chr&gt; &quot;fair&quot;, &quot;gold&quot;, &quot;white, blue&quot;, &quot;white&quot;, &quot;light&quot;, &quot;l... #&gt; $ eye_color &lt;chr&gt; &quot;blue&quot;, &quot;yellow&quot;, &quot;red&quot;, &quot;yellow&quot;, &quot;brown&quot;, &quot;blue&quot;,... #&gt; $ birth_year &lt;dbl&gt; 19.0, 112.0, 33.0, 41.9, 19.0, 52.0, 47.0, NA, 24.0... #&gt; $ gender &lt;chr&gt; &quot;male&quot;, NA, NA, &quot;male&quot;, &quot;female&quot;, &quot;male&quot;, &quot;female&quot;,... #&gt; $ homeworld &lt;chr&gt; &quot;Tatooine&quot;, &quot;Tatooine&quot;, &quot;Naboo&quot;, &quot;Tatooine&quot;, &quot;Alder... #&gt; $ species &lt;chr&gt; &quot;Human&quot;, &quot;Droid&quot;, &quot;Droid&quot;, &quot;Human&quot;, &quot;Human&quot;, &quot;Human... #&gt; $ films &lt;list&gt; [&lt;&quot;Revenge of the Sith&quot;, &quot;Return of the Jedi&quot;, &quot;Th... #&gt; $ vehicles &lt;list&gt; [&lt;&quot;Snowspeeder&quot;, &quot;Imperial Speeder Bike&quot;&gt;, &lt;&gt;, &lt;&gt;,... #&gt; $ starships &lt;list&gt; [&lt;&quot;X-wing&quot;, &quot;Imperial shuttle&quot;&gt;, &lt;&gt;, &lt;&gt;, &quot;TIE Adva... The following code chunk starwars %&gt;% count(homeworld) could be read as, start with the starwars object, then count the number of observations n by homeworld Because each observation in starwars is a person, count() yields the number of people from a given homeworld. The result is: #&gt; # A tibble: 49 x 2 #&gt; homeworld n #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 &lt;NA&gt; 10 #&gt; 2 Alderaan 3 #&gt; 3 Aleen Minor 1 #&gt; 4 Bespin 1 #&gt; 5 Bestine IV 1 #&gt; 6 Cato Neimoidia 1 #&gt; 7 Cerea 1 #&gt; 8 Champala 1 #&gt; 9 Chandrila 1 #&gt; 10 Concord Dawn 1 #&gt; # ... with 39 more rows The pipe makes a sequence of operations easy to construct and easy to read, starwars %&gt;% count(homeworld) %&gt;% arrange(desc(n)) %&gt;% filter(n &gt;= 3) %&gt;% drop_na() which can be read as, start with the starwars object, then count the number of observations n by homeworld, then arrange the rows in descending order of n, then filter to keep all rows where \\(n \\ge 3\\), then drop rows with NA The output is #&gt; # A tibble: 5 x 2 #&gt; homeworld n #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Naboo 11 #&gt; 2 Tatooine 10 #&gt; 3 Alderaan 3 #&gt; 4 Coruscant 3 #&gt; 5 Kamino 3 4.1.10 Keyboard shortcuts In Windows, Ctrl L clears the Console Alt - creates the assignment operator &lt;- Ctrl Enter runs the selected line(s) of code in an R script Feel free to take a break before starting the next tutorial. ▲ top of page 4.2 Graph basics Decline by Randall Munroe (xkcd.com) is licensed under CC BY-NC 2.5 An introduction to ggplot2 adapted from Chapter 3 from (Healy, 2019b). If you already have R experience, you might still want to browse this section in case you find something new. If the prerequisites have been met, the tutorial should take no longer than 50 minutes. 4.2.1 Prerequisites Every tutorial assumes that You completed the Getting started instructions You launched midfield_institute.Rproj to start the R session Use File &gt; New File &gt; R Script to create a new R script Name the script 02-graph-basics.R Save it in the scripts directory Add a minimal header at the top of the script (if you wish) Use library() to load the packages we will use # workshop graph basics # name # date library(&quot;tidyverse&quot;) library(&quot;gapminder&quot;) Run the script by clicking the Source button. If you see an error like this one, Error in library(&quot;pkg_name&quot;) : there is no package called &#39;pkg_name&#39; then you should install the missing package(s) and run the script again. [To review how to install an R package] Guidelines As you work through the tutorial, type a line or chunk of code then File &gt; Save and Source. Confirm that your result matches the tutorial result. Your turn exercises give you chance to devise your own examples and check them out. You learn by doing (but you knew that already)! 4.2.2 Tidy data If the data set is “tidy”, then every row is an observation and every column is a variable. The gapminder data frame is tidy. We use glimpse() to get a look at the structure. glimpse(gapminder) #&gt; Observations: 1,704 #&gt; Variables: 6 #&gt; $ country &lt;fct&gt; Afghanistan, Afghanistan, Afghanistan, Afghanistan, ... #&gt; $ continent &lt;fct&gt; Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia... #&gt; $ year &lt;int&gt; 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992... #&gt; $ lifeExp &lt;dbl&gt; 28.801, 30.332, 31.997, 34.020, 36.088, 38.438, 39.8... #&gt; $ pop &lt;int&gt; 8425333, 9240934, 10267083, 11537966, 13079460, 1488... #&gt; $ gdpPercap &lt;dbl&gt; 779.4453, 820.8530, 853.1007, 836.1971, 739.9811, 78... And we can just type its name to see the first few rows, gapminder #&gt; # A tibble: 1,704 x 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Afghanistan Asia 1952 28.8 8425333 779. #&gt; 2 Afghanistan Asia 1957 30.3 9240934 821. #&gt; 3 Afghanistan Asia 1962 32.0 10267083 853. #&gt; 4 Afghanistan Asia 1967 34.0 11537966 836. #&gt; 5 Afghanistan Asia 1972 36.1 13079460 740. #&gt; 6 Afghanistan Asia 1977 38.4 14880372 786. #&gt; 7 Afghanistan Asia 1982 39.9 12881816 978. #&gt; 8 Afghanistan Asia 1987 40.8 13867957 852. #&gt; 9 Afghanistan Asia 1992 41.7 16317921 649. #&gt; 10 Afghanistan Asia 1997 41.8 22227415 635. #&gt; # ... with 1,694 more rows Read more about tidy data in (Wickham and Grolemund, 2017). Your turn. The ggplot2 package includes a dataset called mpg. Use glimpse() to examine the data set. How many variables? How many observations? How many of the variables are numeric? How many are character type? Is the data set tidy? Check your work. There are 234 observations and 11 variables. 4.2.3 Anatomy of a graph ggplot() is a our basic plotting function. The data = ... argument assigns the data frame. p &lt;- ggplot(data = gapminder) Next we use the mapping argument mapping = aes(...) to assign variables (column names) from the data frame to specific aesthetic properties of the graph such as the x-coordinate, the y-coordinate color, fill, etc. Here we will map the GDP per capita variable to x and the life expectancy variable to y. p &lt;- ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp)) If we try to print the graph by typing the name of the graph object (everything in R is an object), we get an empty graph because we haven’t told ggplot what sort of a graph we want. p Because the graph will be a scatterplot, we add the geom_point() layer. p &lt;- p +geom_point() p # display the graph In ggplot2, “geoms” are geometric objects such as points, lines, bars, boxplots, contours, polygons, etc. You can browse the full list on the ggplot2 geom reference page. We could also have simply added the layer to the original object, p &lt;- ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp)) + geom_point() p # display the graph Notice that the default axis labels are the variables names from the data frame. We can edit those with another layer p &lt;- p + labs(x = &quot;GDP per capita&quot;, y = &quot;Life expectancy (years)&quot;) p # display the graph Or, with all layers shown in one code chunk, p &lt;- ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp)) + geom_point() + labs(x = &quot;GDP per capita&quot;, y = &quot;Life expectancy (years)&quot;) p # display the graph Summary. The basics steps for building up the layers of any graph consist of, assign the data frame map variables (columns names) to aesthetic properties choose geoms adjust scales, labels, etc. For more information aes() help page geom_point() help page geom_labs() help page Your turn. In the console, type ? mpg to see the data set help page. Skim the descriptions of the variables. Create a scatterplot of highway miles per gallon as a function of engine displacement in liters. Check your work: 4.2.4 Layer: smooth fit Suppose you wanted a smooth fit curve, not necessarily linear. Add a geom_smooth() layer. The name loess (pronounced like the proper name Lois) is a nonparametric curve-fitting method based on local regression. p &lt;- p + geom_smooth(method = &quot;loess&quot;, se = FALSE) p # display the graph The se argument controls whether or not the confidence interval is displayed. Setting se = TRUE yields, p &lt;- p + geom_smooth(method = &quot;loess&quot;, se = TRUE) p # display the graph For a linear-fit layer, we add a layer with method set to lm (short for linear model). The linear fit is not particularly good in this case, but now you know how to do one. p &lt;- p + geom_smooth(method = &quot;lm&quot;, se = TRUE) p # display the graph For more information geom_smooth() help page Your turn. Continue to practice with mpg. Add a loess curve fit with a confidence interval. Check your work: 4.2.5 Layer: log scale We have orders of magnitude differences in the GDP per capita variable. To confirm, we can create a summary() of the gdpPercap variable. The output shows that the minimum is 241, the median 3532, and the maximum 113523. # extract one variable from the data frame this_variable &lt;- gapminder[&quot;gdpPercap&quot;] # statistical summary of one variable summary(this_variable) #&gt; gdpPercap #&gt; Min. : 241.2 #&gt; 1st Qu.: 1202.1 #&gt; Median : 3531.8 #&gt; Mean : 7215.3 #&gt; 3rd Qu.: 9325.5 #&gt; Max. :113523.1 The bracket notation I just used, gapminder[\"gdpPercap\"], is one way to extract a variable from a data frame. In exploring a graph like this, it might be useful to add a layer that changes the horizontal scale to a log-base-10 scale. p &lt;- ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp)) + geom_point() + scale_x_log10() p # display the graph The scales package allows us to change the GDP scale to dollars. Using the syntax thepackage::thefunction we can use the scales::dollar function without loading the scales package. p &lt;- ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp)) + geom_point() + scale_x_log10(labels = scales::dollar) p # display the graph In this case, a linear fit might work, p &lt;- p + geom_smooth(method = &quot;lm&quot;, se = TRUE) p # display the graph Update the axis labels, p &lt;- p + labs(x = &quot;GDP per capita (log10 scale)&quot;, y = &quot;Life expectancy (years)&quot;) p # display the graph In summary, all the layers could have been be coded at once, for example, p &lt;- ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp)) + geom_point() + geom_smooth(method = &quot;lm&quot;, se = TRUE) + scale_x_log10(labels = scales::dollar) + labs(x = &quot;GDP per capita (log10 scale)&quot;, y = &quot;Life expectancy (years)&quot;) With all the layers in one place, we can see that we’ve coded all the basic steps, that is, assign the data frame map variables (columns names) to aesthetic properties choose geoms adjust scales, labels, etc. For more information scale_x_log10() help page Your turn. Continue to practice with mpg. Edit the axis labels to include units. Check your work: 4.2.6 Mapping aesthetics So far, we have mapped variables only to the x-coordinate and y-coordinate aesthetics. If we map a variable to the color aesthetic, the data symbols are automatically assigned different colors and a legend is created. In this example, we map the continent variable to color. p &lt;- ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() + scale_x_log10(labels = scales::dollar) + labs(x = &quot;GDP per capita&quot;, y = &quot;Life expectancy (years)&quot;) p # print the graph Your turn. Continue to practice with mpg. Map vehicle class to color Change the curve fit to linear Check your work: 4.2.7 Setting properties Because the colors overprint, we might try making the data symbols slightly transparent. In this case, we are not mapping a property to a variable; instead, we want all data symbols to be less opaque. The alpha argument, with \\(0 \\leq \\alpha \\leq 1\\), sets the transparency level. Because this change applies to all data points equally, we assign it in the geom, not aes(). p &lt;- ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point(alpha = 0.3) + scale_x_log10(labels = scales::dollar) + labs(x = &quot;GDP per capita&quot;, y = &quot;Life expectancy (years)&quot;) p # print the graph If we add a linear fit to these data, a fit for each continent is generated. For a thinner line, I’ve added a size argument to the geom. p &lt;- p + geom_smooth(method = &quot;lm&quot;, se = FALSE, size = 0.5) p # print the graph If we want all the data markers the same color but we want to change the color, we don’t map it, we set it in the geom. Here, I’ve omitted the aesthetic mapping to color and used a color assignment in the geom. p &lt;- ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp)) + geom_point(alpha = 0.3, color = &quot;purple1&quot;) + geom_smooth(method = &quot;lm&quot;, se = FALSE, size = 0.5, color = &quot;purple4&quot;) + scale_x_log10(labels = scales::dollar) + labs(x = &quot;GDP per capita (log10 scale)&quot;, y = &quot;Life expectancy (years)&quot;) p # print the graph For more information R color names 4.2.8 Layer: facets In the earlier graph where we mapped continent to color, there was a lot of overprinting, making it difficult to compare the continents. The facet_wrap() layer separates the data into different panels (or facets). Like the aes() mapping, facet_wrap() is applied to a variable (column name) in the data frame. p &lt;- p + facet_wrap(facets = vars(continent)) p # print the graph Comparisons are facilitated by having the facets appear in one column, by using the ncols argument of facet_wrap(). p &lt;- p + facet_wrap(facets = vars(continent), ncol = 1) p # print the graph In a faceted display, all panels have identical scales (the default) to facilitate comparison. Again, all the layers could have been be coded at once, for example, ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp)) + geom_point(alpha = 0.3, color = &quot;purple1&quot;) + geom_smooth(method = &quot;lm&quot;, se = FALSE, size = 0.5, color = &quot;purple4&quot;) + facet_wrap(facets = vars(continent), ncol = 1) + scale_x_log10(labels = scales::dollar) + labs(x = &quot;GDP per capita (log10 scale)&quot;, y = &quot;Life expectancy (years)&quot;) For more information facet_wrap() help page Your turn. Continue to practice with mpg. Map drive type to color Facet on vehicle class Add some transparency to the data symbols Omit the smooth fit Check your work: 4.2.9 Ordering the panels The default ordering of the panels in this example is alphabetical. In most cases, ordering the panels by the data (often the mean or the median) improves the display. Here we have two quantitative variables, but the one that is the more interesting is life expectancy. Our goal then is to order the continent variable by the median of the lifeExp variable in each panel. To do that, we require continent to be a factor, a type of variable specialized for creating ordered levels of a category. Using glimpse() we see that continent is already a factor (&lt;fct&gt;). glimpse(gapminder) #&gt; Observations: 1,704 #&gt; Variables: 6 #&gt; $ country &lt;fct&gt; Afghanistan, Afghanistan, Afghanistan, Afghanistan, ... #&gt; $ continent &lt;fct&gt; Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia... #&gt; $ year &lt;int&gt; 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992... #&gt; $ lifeExp &lt;dbl&gt; 28.801, 30.332, 31.997, 34.020, 36.088, 38.438, 39.8... #&gt; $ pop &lt;int&gt; 8425333, 9240934, 10267083, 11537966, 13079460, 1488... #&gt; $ gdpPercap &lt;dbl&gt; 779.4453, 820.8530, 853.1007, 836.1971, 739.9811, 78... Therefore all we have to do is tell R that we want the levels of continent ordered by the median of life expectancy using the fct_reorder() function. gapminder &lt;- gapminder %&gt;% mutate(continent = fct_reorder(continent, lifeExp, median)) In doing so, I’ve overwritten the original gapminder dataset with my revised version. We set the as.table argument to false to place the panel with the highest life expectancy in the top position. ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp)) + geom_point(alpha = 0.3, color = &quot;purple1&quot;) + geom_smooth(method = &quot;lm&quot;, se = FALSE, size = 0.5, color = &quot;purple4&quot;) + facet_wrap(facets = vars(continent), ncol = 1, as.table = FALSE) + scale_x_log10(labels = scales::dollar) + labs(x = &quot;GDP per capita (log10 scale)&quot;, y = &quot;Life expectancy (years)&quot;) For more information mutate() help page fct_reorder() help page Your turn. Continue to practice with mpg. Convert class to a factor ordered by the mean highway mileage Same graph as before, but order the panels by mean fuel consumption Check your work: 4.2.10 Beyond the basics Demonstrating how the basics can be built upon to create a complex data graphic. To wrap up this introduction, I’ll show you how we can use functions in various layers to show all the data in every panel; add a common overall loess smooth fit; and highlight the the continent data in each panel, making it easier to compare each continent to the global data. Because life expectancy has generally increased over time, I’m going to restrict this final graph to 2007, the most recent year in this dataset. Typing this code in your script is optional. Without further explanation, here’s the code. gapminder &lt;- gapminder %&gt;% filter(year == 2007) ggplot(data = gapminder, mapping = aes(x = gdpPercap / 1000, y = lifeExp)) + geom_point(data = select(gapminder, -continent), size = 1.25, alpha = 0.5, color = &quot;#80cdc1&quot;) + geom_smooth(data = select(gapminder, -continent), method = &quot;loess&quot;, se = FALSE, size = 0.7, color = &quot;#80cdc1&quot;) + geom_point(mapping = aes(color = continent), size = 1.25, color = &quot;#01665e&quot;) + facet_wrap(vars(continent), ncol = 1, as.table = FALSE) + labs(x = &quot;GDP per capita (thousands of dollars)&quot;, y = &quot;Life expectancy (years)&quot;, title = &quot;Life expectancy by country, 2007&quot;, caption = &quot;Source: Gapminder&quot;) + theme(legend.position = &quot;none&quot;) For more information select() help page filter() help page theme() help page ColorBrewer for color hex codes 4.2.11 Resize and write to file For consistent control over the size and aspect ratio of your publication-ready graph, you should always conclude your design by saving the image and sizing it at the same time. Here, we save the figure to the figures directory we set up earlier. ggsave(filename = &quot;figures/02-graph-basics-gapminder.png&quot;, width = 6.5, height = 10.5, units = &quot;in&quot;, dpi = 300) And the final figure looks like this: For more information ggsave() help page Your turn. Continue to practice with mpg. Write your ggsave() code chunk immediately following the ggplot() code chunk of the graph you want to save. Use ggsave to write your graph to the figures directory with the name 02-graph-basics-mpg.png Try a 6 in by 6 in figure size Check your work: Navigate to your figures folder. The new png file should be there. Open it to confirm it is the figure you expect. Feel free to take a break before starting the next tutorial. ▲ top of page 4.3 Data basics In Tidy Data, Hadley Wickham says, It is often said that 80% of data analysis is spent on the process of cleaning and preparing the data. Data preparation is not just a first step, but must be repeated many times over the course of analysis as new problems come to light or new data is collected [emphasis mine]. That data preparation “must be repeated many times” cannot be overemphasized. Reproducibility starts with deliberate planning for data management, file management, and file-naming schemes and using a scripted computing environment like R (or Python, SAS, etc.). Other researchers may never attempt to reproduce your work—but you will. Data preparation “must be repeated many times.” As Karl Broman once said, Your closest collaborator is you six months ago, but you don’t reply to emails. The goal of this 50-minute tutorial is to introduce three basic steps of data preparation: importing data, identifying its structure, and reshaping to obtain a desired form. Step 1. Importing raw data and writing to file. Step 2. Identifying the data structure. Step 3. Transforming, reshaping, and joining. 4.3.1 Prerequisites Every tutorial assumes that You completed the Getting started instructions You launched midfield_institute.Rproj to start the R session Use File &gt; New File &gt; R Script to create a new R script Name the script 03-data-basics.R Save it in the scripts directory Add a minimal header at the top of the script (if you wish) Use library() to load the packages we will use # workshop data basics # name # date library(&quot;tidyverse&quot;) library(&quot;lubridate&quot;) library(&quot;seplyr&quot;) library(&quot;rio&quot;) library(&quot;inspectdf&quot;) Run the script by clicking the Source button. If you see an error like this one, Error in library(&quot;pkg_name&quot;) : there is no package called &#39;pkg_name&#39; then you should install the missing package(s) and run the script again. [To review how to install an R package] Guidelines As you work through the tutorial, type a line or chunk of code then File &gt; Save and Source. Confirm that your result matches the tutorial result. Your turn exercises give you chance to devise your own examples and check them out. You learn by doing (but you knew that already)! 4.3.2 Data sets in R Practice data sets are included with the basic R installation and with some R packages. To list the practice data sets available in R, type in the Console, # type in the Console data() which yields #&gt; AirPassengers Monthly Airline Passenger Numbers #&gt; BJsales Sales Data with Leading Indicator #&gt; BOD Biochemical Oxygen Demand #&gt; CO2 Carbon Dioxide Uptake in Grass Plants #&gt; Formaldehyde Determination of Formaldehyde etc. We use the data() function to list practice datasets included in a package (if any). For example, to determine what packages are bundled with the dplyr package, type in the Console, # type in the Console data(package = &quot;dplyr&quot;) yields #&gt; band_instruments Band membership #&gt; band_instruments2 Band membership #&gt; band_members Band membership #&gt; nasa NASA spatio-temporal data #&gt; starwars Starwars characters #&gt; storms Storm tracks data Every data set in base R and in R packages has a help page that describes the data format and variable names. The data help page can be accessed using help(), for example, # type in the Console help(starwars, package = &quot;dplyr&quot;) Alternatively, if the package is loaded, you may run the ? item-name syntax in the Console, # type in the Console library(&quot;dplyr&quot;) ? starwars yields Your turn. These exercises assume that you have successfully followed the instructions to install midfielddata and midfieldr. Determine the names of the datasets available in the midfieldr package. Check your work Determine the variables in case_stickiness (one of the datasets in the midfieldr package). Check your work Determine the names of the datasets available in the midfielddata package. Check your work Determine the variables in midfielddegrees (one of the datasets in the midfielddata package). Check your work 4.3.3 Data structure When we first encounter any data set, the first step is to characterize its structure including, the R data structure, e.g., vector, matrix, data frame, time series, list, etc. the number of observations the number of variables the name and class of each variable To do so, we use functions like glimpse() and class() (introduced in R basics) as well as functions from the inspectdf package (introduced in the next section). [To read more about R data structures] [To read more about inspectdf] 4.3.4 Example: Create a 2018 price index Over any time period with inflation, a dollar buys less at the end the period than it did at the beginning of the period. Thus, in 1973 a single 20-year old could live comfortably on $5/hour but in 2018 (45 years later) a 20-year-old has to earn $30/hour to achieve the same modest standard of living. We usually adjust for the effects of inflation in US dollars using the Consumer Price Index (CPI) published by the US Bureau of Labor Statistics (BLS). The CPI is available by month from the BLS or from the Federal Reserve (FRED), from 1913 to the present. In this example, we obtain historical Consumer Price Index data from the Federal Reserve (FRED) and perform the necessary data carpentry to graph a price index with respect to 2018 dollars. Step 1. Importing raw data and writing to file. The FRED provides CPI data from 1913 to the present as a .txt file at the URL: http://research.stlouisfed.org/fred2/data/CPIAUCNS.txt If you click on the link, you can see that the first 13 lines are metadata. The data starts on line 14 with the column names. I’ve added line numbers to make it easier to see. 1 Title: Consumer Price Index for All Urban Consumers: All Items 2 Series ID: CPIAUCNS 3 Source: U.S. Bureau of Labor Statistics 4 Release: Consumer Price Index 5 Seasonal Adjustment: Not Seasonally Adjusted 6 Frequency: Monthly 7 Units: Index 1982-1984=100 8 Date Range: 1913-01-01 to 2019-04-01 9 Last Updated: 2019-05-10 7:42 AM CDT 10 Notes: Handbook of Methods - (https://www.bls.gov/opub/hom/pdf/cpihom.pdf) 11 Understanding the CPI: Frequently Asked Questions - 12 (https://www.bls.gov/cpi/questions-and-answers.htm) 13 14 DATE VALUE 15 1913-01-01 9.800 16 1913-02-01 9.800 etc. Assign the URL (add these lines to your script and run) url &lt;- &quot;http://research.stlouisfed.org/fred2/data/CPIAUCNS.txt&quot; Use rio::import() to download the data, skipping the first 13 lines x &lt;- rio::import(url, skip = 13) Use rio::export() to convert the txt file to CSV and write to our data directory rio::export(x, &quot;data/cpi-raw.csv&quot;) Once you have saved raw data to file (like we did above), leave that file unaltered. Never manipulate raw data manually. In this workshop, we are saving all data files to the data directory. In larger projects, one might add a data-raw directory to separate raw data files from prepared data files. We don’t have to re-import the data from the Internet every time we Source this R script, so we can comment-out the previous three lines of code with a hashtag, i.e., # url &lt;- &quot;http://research.stlouisfed.org/fred2/data/CPIAUCNS.txt&quot; # x &lt;- rio::import(url, skip = 13) # rio::export(x, &quot;data/cpi-raw.csv&quot;) Step 2. Identifying the data structure. Use rio::import() to read the raw data into the R workspace. cpi &lt;- rio::import(&quot;data/cpi-raw.csv&quot;) Use class() to determine the R data structure—in this case, cpi is a tibble (a type of data frame). class(cpi) #&gt; [1] &quot;data.frame&quot; Use glimpse() to examine the tibble—we discover the number of observations (1276), the number of variables (2), their names (DATE, VALUE), and their class or type (character, double). glimpse(cpi) #&gt; Observations: 1,276 #&gt; Variables: 2 #&gt; $ DATE &lt;chr&gt; &quot;1913-01-01&quot;, &quot;1913-02-01&quot;, &quot;1913-03-01&quot;, &quot;1913-04-01&quot;, ... #&gt; $ VALUE &lt;dbl&gt; 9.8, 9.8, 9.8, 9.8, 9.7, 9.8, 9.9, 9.9, 10.0, 10.0, 10.1... The first DATE values suggest these are monthly data, which agrees with the frequency given in the block of metadata. The VALUE variable is the CPI by month indexed at 1982–1984 (for which CPI = 100). These data are in what Hadley Wickham calls “tidy” form, that is, Each variable is in a column Each observation is a row Each value is a cell Such an organization is also called a “data matrix” or a “de-normalized form” (Mount, 2019). This form is typically the desired form for data visualization using the ggplot2 package, though other forms are sometimes useful. Functions from the inspectdf package can tell us more about the data. First, we summarize memory usage. Here, both variable use negligible memory. inspect_mem(cpi) # memory #&gt; # A tibble: 2 x 3 #&gt; col_name size pcnt #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 DATE 89.77 Kb 90.0 #&gt; 2 VALUE 10.02 Kb 10.0 Summarize the rate of missingness. Here, there are no missing values. inspect_na(cpi) # NAs #&gt; # A tibble: 2 x 3 #&gt; col_name cnt pcnt #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 DATE 0 0 #&gt; 2 VALUE 0 0 Summary 1276 observations, one per month, 1913-01 to 2019-04 1 categorical variable DATE 1 quantitative variable VALUE (the CPI) Your turn. For the midfielddegrees dataset from the midfielddata package, determine the R data structure, e.g., vector, matrix, time series, data frame, tibble, etc. the number of observations the number of variables the name and class of each variable summary of missing values summary of missing values Check your work: A tibble with 97640 observations and 5 variables. The variable that requires the most memory is id with 6.7 Mb. Three of the variables have 51% missing values. Step 3. Transforming, reshaping, and joining. For the application I have in mind, I want to convert monthly CPI to annual CPI. I start by changing the variable names (the column names) because I prefer lowercase names and I prefer meaningful file names (cpi instead of VALUE). Use dplyr::rename(new_name = old_name) to rename the variables. cpi &lt;- cpi %&gt;% dplyr::rename(date = DATE, cpi = VALUE) %&gt;% glimpse() #&gt; Observations: 1,276 #&gt; Variables: 2 #&gt; $ date &lt;chr&gt; &quot;1913-01-01&quot;, &quot;1913-02-01&quot;, &quot;1913-03-01&quot;, &quot;1913-04-01&quot;, &quot;... #&gt; $ cpi &lt;dbl&gt; 9.8, 9.8, 9.8, 9.8, 9.7, 9.8, 9.9, 9.9, 10.0, 10.0, 10.1,... Before I can average the monthly CPIs by year, I need to extract the 4-digit year from the date variable. Use lubridate::year() to extract the year from the date and mutate() to create the new year variable. cpi &lt;- cpi %&gt;% mutate(year = lubridate::year(date)) %&gt;% glimpse() #&gt; Observations: 1,276 #&gt; Variables: 3 #&gt; $ date &lt;chr&gt; &quot;1913-01-01&quot;, &quot;1913-02-01&quot;, &quot;1913-03-01&quot;, &quot;1913-04-01&quot;, &quot;... #&gt; $ cpi &lt;dbl&gt; 9.8, 9.8, 9.8, 9.8, 9.7, 9.8, 9.9, 9.9, 10.0, 10.0, 10.1,... #&gt; $ year &lt;dbl&gt; 1913, 1913, 1913, 1913, 1913, 1913, 1913, 1913, 1913, 191... Use filter() to omit 2019 data because we do not have a full year. Note the reduction in the number of observations. cpi &lt;- cpi %&gt;% filter(year != 2019) %&gt;% glimpse() #&gt; Observations: 1,272 #&gt; Variables: 3 #&gt; $ date &lt;chr&gt; &quot;1913-01-01&quot;, &quot;1913-02-01&quot;, &quot;1913-03-01&quot;, &quot;1913-04-01&quot;, &quot;... #&gt; $ cpi &lt;dbl&gt; 9.8, 9.8, 9.8, 9.8, 9.7, 9.8, 9.9, 9.9, 10.0, 10.0, 10.1,... #&gt; $ year &lt;dbl&gt; 1913, 1913, 1913, 1913, 1913, 1913, 1913, 1913, 1913, 191... Use arrange() and tail() to confirm that 2018 is the final year. cpi %&gt;% arrange(date) %&gt;% tail() #&gt; date cpi year #&gt; 1267 2018-07-01 252.006 2018 #&gt; 1268 2018-08-01 252.146 2018 #&gt; 1269 2018-09-01 252.439 2018 #&gt; 1270 2018-10-01 252.885 2018 #&gt; 1271 2018-11-01 252.038 2018 #&gt; 1272 2018-12-01 251.233 2018 Use seplyr::group_summarize() operation to determine the average annual CPI. grouping_variables &lt;- c(&quot;year&quot;) cpi_1984_basis &lt;- seplyr::group_summarize(cpi, grouping_variables, cpi = mean(cpi)) %&gt;% glimpse() #&gt; Observations: 106 #&gt; Variables: 2 #&gt; $ year &lt;dbl&gt; 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 192... #&gt; $ cpi &lt;dbl&gt; 9.883333, 10.016667, 10.108333, 10.883333, 12.825000, 15.... We have an excess of significant digits. Use round() to reduce our annual CPI values to 2 digits. cpi_1984_basis &lt;- cpi_1984_basis %&gt;% mutate(cpi = round(cpi, 2)) %&gt;% glimpse() #&gt; Observations: 106 #&gt; Variables: 2 #&gt; $ year &lt;dbl&gt; 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 192... #&gt; $ cpi &lt;dbl&gt; 9.88, 10.02, 10.11, 10.88, 12.82, 15.04, 17.33, 20.04, 17... These values can be displayed, ggplot(data = cpi_1984_basis, mapping = aes(x = year, y = cpi)) + geom_line() + labs(title = &quot;CPI with a 1983--1984 basis&quot;) As expected, in 1983–1984 (the basis years), CPI = 100. To shift the basis year to 2018, we extract the CPI for 2018, cpi_2018 &lt;- cpi_1984_basis %&gt;% filter(year == 2018) %&gt;% select(cpi) %&gt;% unlist(use.names = FALSE) cpi_2018 #&gt; [1] 251.11 Then divide all CPI values by the 2018 value to create the price index with a 2018 basis. In the basis year, the index = 1. cpi_2018_basis &lt;- cpi_1984_basis %&gt;% mutate(index = cpi / cpi_2018) %&gt;% glimpse() #&gt; Observations: 106 #&gt; Variables: 3 #&gt; $ year &lt;dbl&gt; 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 19... #&gt; $ cpi &lt;dbl&gt; 9.88, 10.02, 10.11, 10.88, 12.82, 15.04, 17.33, 20.04, 1... #&gt; $ index &lt;dbl&gt; 0.03934531, 0.03990283, 0.04026124, 0.04332763, 0.051053... Graph the price index, ggplot(data = cpi_2018_basis, mapping = aes(x = year, y = index)) + geom_line() + labs(title = &quot;Price index with a 2018 basis&quot;) The price index is used to account for inflation for any US dollar amount from 1913 to 2018 and report the results in terms of constant 2018 dollars. One simply divides the nominal dollar value by the price index for that year. Now that the data are prepared, we write them to file. rio::export(cpi_2018_basis, &quot;data/cpi.csv&quot;) 4.3.5 Example: Normalized housing costs In this example we retrieve nominal US housing costs from the OECD database. Step 1. Importing raw data and writing to file. The long URL string below retrieves US housing costs by year from the OECD database. These are nominal costs (not adjusted for inflation) and normalized to a basis year of 2015, that is, the median house price is 100 in 2015. We start by importing the data and writing it to file. url &lt;- &quot;https://stats.oecd.org/sdmx-json/data/DP_LIVE/USA.HOUSECOST.NOMINAL.IDX2015.A/OECD?contentType=csv&amp;detail=code&amp;separator=comma&amp;csv-lang=en&amp;startPeriod=1956&amp;endPeriod=2018&quot; x &lt;- rio::import(url, format = &quot;csv&quot;) rio::export(x, &quot;data/housing-raw.csv&quot;) Again, after doing this once, we can comment-out these three lines of code so we don’t have to access the internet every time we Source this script. # url &lt;- &quot;https://stats.oecd.org/sdmx-json/data/DP_LIVE/USA.HOUSECOST.NOMINAL.IDX2015.A/OECD?contentType=csv&amp;detail=code&amp;separator=comma&amp;csv-lang=en&amp;startPeriod=1956&amp;endPeriod=2018&quot; # x &lt;- rio::import(url, format = &quot;csv&quot;) # rio::export(x, &quot;data/housing-raw.csv&quot;) Step 2. Identifying the data structure. Read in the CSV file and examine it. Here, we have 49 observations of 8 variables in tidy form. housing &lt;- rio::import(&quot;data/housing-raw.csv&quot;) %&gt;% glimpse() #&gt; Observations: 49 #&gt; Variables: 8 #&gt; $ LOCATION &lt;chr&gt; &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, ... #&gt; $ INDICATOR &lt;chr&gt; &quot;HOUSECOST&quot;, &quot;HOUSECOST&quot;, &quot;HOUSECOST&quot;, &quot;HOUSECOST... #&gt; $ SUBJECT &lt;chr&gt; &quot;NOMINAL&quot;, &quot;NOMINAL&quot;, &quot;NOMINAL&quot;, &quot;NOMINAL&quot;, &quot;NOMI... #&gt; $ MEASURE &lt;chr&gt; &quot;IDX2015&quot;, &quot;IDX2015&quot;, &quot;IDX2015&quot;, &quot;IDX2015&quot;, &quot;IDX2... #&gt; $ FREQUENCY &lt;chr&gt; &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;,... #&gt; $ TIME &lt;int&gt; 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1... #&gt; $ Value &lt;dbl&gt; 11.16166, 12.06250, 12.92855, 14.46220, 15.78472,... #&gt; $ `Flag Codes` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... We asked for data starting from 1956, but the US data in this database apparently starts in 1970, hence 49 observations, one per year, from 1970 to 2019. We have two numerical variables for year and normalized housing value; of the remaining variables, one is logical and the rest are categorical. We cam summarize the categorical variables using inspect_cat(). inspect_cat(housing) #&gt; # A tibble: 6 x 5 #&gt; col_name cnt common common_pcnt levels #&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;list&gt; #&gt; 1 Flag Codes 1 &lt;NA&gt; 100 &lt;tibble [1 x 3]&gt; #&gt; 2 FREQUENCY 1 A 100 &lt;tibble [1 x 3]&gt; #&gt; 3 INDICATOR 1 HOUSECOST 100 &lt;tibble [1 x 3]&gt; #&gt; 4 LOCATION 1 USA 100 &lt;tibble [1 x 3]&gt; #&gt; 5 MEASURE 1 IDX2015 100 &lt;tibble [1 x 3]&gt; #&gt; 6 SUBJECT 1 NOMINAL 100 &lt;tibble [1 x 3]&gt; Here, the count of the number of levels for every categorical variable is 1, e.g., indicator = house cost, location = US, etc, indicating that these variables have a constant value for all years. Memory usage is small and there are no missing values. inspect_mem(housing) #&gt; # A tibble: 8 x 3 #&gt; col_name size pcnt #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 INDICATOR 504 bytes 14.7 #&gt; 2 LOCATION 496 bytes 14.5 #&gt; 3 SUBJECT 496 bytes 14.5 #&gt; 4 MEASURE 496 bytes 14.5 #&gt; 5 FREQUENCY 496 bytes 14.5 #&gt; 6 Value 440 bytes 12.9 #&gt; 7 TIME 248 bytes 7.24 #&gt; 8 Flag Codes 248 bytes 7.24 inspect_na(housing) #&gt; # A tibble: 8 x 3 #&gt; col_name cnt pcnt #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Flag Codes 49 100 #&gt; 2 LOCATION 0 0 #&gt; 3 INDICATOR 0 0 #&gt; 4 SUBJECT 0 0 #&gt; 5 MEASURE 0 0 #&gt; 6 FREQUENCY 0 0 #&gt; 7 TIME 0 0 #&gt; 8 Value 0 0 Summary 49 observations, one per year, 1970–2019 2 quantitative variables are of interest: TIME and Value the remaining categorical and logical variables are not relevant to our inquiry Step 3. Transforming, reshaping, and joining. We want to keep the TIME and Value columns and rename them. housing_2015_basis &lt;- housing %&gt;% select(TIME, Value) %&gt;% dplyr::rename(year = TIME, nominal = Value) %&gt;% glimpse() #&gt; Observations: 49 #&gt; Variables: 2 #&gt; $ year &lt;int&gt; 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, ... #&gt; $ nominal &lt;dbl&gt; 11.16166, 12.06250, 12.92855, 14.46220, 15.78472, 16.7... The costs have been normalized with a 2015 basis, that is in 2015, the price is 100. I’d like to normalize these data to 2018 costs by dividing all nominal values by the one recorded for 2018, then multiply by 100, so that the $100 price value is in the same basis year as my price index. First, find the 2018 nominal house cost. nominal_2018 &lt;- housing_2015_basis %&gt;% filter(year == 2018) %&gt;% select(nominal) %&gt;% unlist(use.names = FALSE) nominal_2018 #&gt; [1] 120.3783 Then adjust the costs so that the basis year is 2018. housing_2018_basis &lt;- housing_2015_basis %&gt;% mutate(nominal = nominal / nominal_2018 * 100) Check the tail of the data frame to confirm that the 2018 value is 100. tail(housing_2018_basis, n = 10L) #&gt; year nominal #&gt; 40 2009 73.30078 #&gt; 41 2010 71.12164 #&gt; 42 2011 68.12677 #&gt; 43 2012 70.10484 #&gt; 44 2013 75.07875 #&gt; 45 2014 78.88267 #&gt; 46 2015 83.07147 #&gt; 47 2016 88.01283 #&gt; 48 2017 93.81684 #&gt; 49 2018 100.00000 We can graph this for a look at relative nominal housing costs in the US. ggplot(data = housing_2018_basis, mapping = aes(x = year, y = nominal)) + geom_line() + labs(title = &quot;Normalized US median housing cost&quot;, subtitle = &quot;Not adjusted for inflation&quot;) Now that the data are prepared, we write them to file. rio::export(housing_2018_basis, &quot;data/housing.csv&quot;) 4.3.6 Example: Real US housing costs In this final example, we join the two data frames we created previously and adjust the US housing costs for inflation. The raw data have already been prepared, so we can continue step 3. Step 3. Transforming, reshaping, and joining. Read in the two data frames we saved earlier. Recall that both have been transformed to use a 2018 basis. cpi &lt;- rio::import(&quot;data/cpi.csv&quot;) housing &lt;- rio::import(&quot;data/housing.csv&quot;) The CPI data spans 1913 to 2018, with the index = 1 in 2018. head(cpi) #&gt; year cpi index #&gt; 1 1913 9.88 0.03934531 #&gt; 2 1914 10.02 0.03990283 #&gt; 3 1915 10.11 0.04026124 #&gt; 4 1916 10.88 0.04332763 #&gt; 5 1917 12.82 0.05105332 #&gt; 6 1918 15.04 0.05989407 tail(cpi) #&gt; year cpi index #&gt; 101 2013 232.96 0.9277209 #&gt; 102 2014 236.74 0.9427741 #&gt; 103 2015 237.02 0.9438891 #&gt; 104 2016 240.01 0.9557963 #&gt; 105 2017 245.12 0.9761459 #&gt; 106 2018 251.11 1.0000000 The housing data spans 1970 to 2018, with nominal cost = 100 in 2018. head(housing) #&gt; year nominal #&gt; 1 1970 9.272153 #&gt; 2 1971 10.020497 #&gt; 3 1972 10.739936 #&gt; 4 1973 12.013966 #&gt; 5 1974 13.112603 #&gt; 6 1975 13.930902 tail(housing) #&gt; year nominal #&gt; 44 2013 75.07875 #&gt; 45 2014 78.88267 #&gt; 46 2015 83.07147 #&gt; 47 2016 88.01283 #&gt; 48 2017 93.81684 #&gt; 49 2018 100.00000 Use left_join() to combine the two data frames, joining cpi to housing housing_cpi &lt;- left_join(housing, cpi, by = &quot;year&quot;) head(housing_cpi) #&gt; year nominal cpi index #&gt; 1 1970 9.272153 38.83 0.1546334 #&gt; 2 1971 10.020497 40.49 0.1612441 #&gt; 3 1972 10.739936 41.82 0.1665406 #&gt; 4 1973 12.013966 44.40 0.1768149 #&gt; 5 1974 13.112603 49.31 0.1963681 #&gt; 6 1975 13.930902 53.82 0.2143284 tail(housing_cpi) #&gt; year nominal cpi index #&gt; 44 2013 75.07875 232.96 0.9277209 #&gt; 45 2014 78.88267 236.74 0.9427741 #&gt; 46 2015 83.07147 237.02 0.9438891 #&gt; 47 2016 88.01283 240.01 0.9557963 #&gt; 48 2017 93.81684 245.12 0.9761459 #&gt; 49 2018 100.00000 251.11 1.0000000 Usage: left_join(x, y, by) returns all rows from x and all columns from x and y. ‘by’ is a character vector of variables (column names) that x and y have in common used to join the two data frames. In this case, we left-join cpi (y) to housing (x) because housing has fewer years. Had we reversed the order of the two data frames, rows in x with no match in y will have NA values in the new columns, i.e., test &lt;- left_join(cpi, housing, by = &quot;year&quot;) head(test) #&gt; year cpi index nominal #&gt; 1 1913 9.88 0.03934531 NA #&gt; 2 1914 10.02 0.03990283 NA #&gt; 3 1915 10.11 0.04026124 NA #&gt; 4 1916 10.88 0.04332763 NA #&gt; 5 1917 12.82 0.05105332 NA #&gt; 6 1918 15.04 0.05989407 NA tail(test) #&gt; year cpi index nominal #&gt; 101 2013 232.96 0.9277209 75.07875 #&gt; 102 2014 236.74 0.9427741 78.88267 #&gt; 103 2015 237.02 0.9438891 83.07147 #&gt; 104 2016 240.01 0.9557963 88.01283 #&gt; 105 2017 245.12 0.9761459 93.81684 #&gt; 106 2018 251.11 1.0000000 100.00000 The real housing cost is determined by dividing the nominal cost by the price index, housing_cpi &lt;- housing_cpi %&gt;% mutate(real = nominal / index) head(housing_cpi) #&gt; year nominal cpi index real #&gt; 1 1970 9.272153 38.83 0.1546334 59.96215 #&gt; 2 1971 10.020497 40.49 0.1612441 62.14490 #&gt; 3 1972 10.739936 41.82 0.1665406 64.48841 #&gt; 4 1973 12.013966 44.40 0.1768149 67.94656 #&gt; 5 1974 13.112603 49.31 0.1963681 66.77562 #&gt; 6 1975 13.930902 53.82 0.2143284 64.99793 tail(housing_cpi) #&gt; year nominal cpi index real #&gt; 44 2013 75.07875 232.96 0.9277209 80.92816 #&gt; 45 2014 78.88267 236.74 0.9427741 83.67080 #&gt; 46 2015 83.07147 237.02 0.9438891 88.00978 #&gt; 47 2016 88.01283 240.01 0.9557963 92.08325 #&gt; 48 2017 93.81684 245.12 0.9761459 96.10944 #&gt; 49 2018 100.00000 251.11 1.0000000 100.00000 Graphing normalized median US housing costs in real (constant 2018) dollars, we have, ggplot(data = housing_cpi, mapping = aes(x = year, y = real)) + geom_line() + labs(title = &quot;Normalized US median housing cost&quot;, subtitle = &quot;Constant 2018 dollars&quot;) From the graph, a monthly housing cost of $100 in 2018 is equivalent to approximately $70 in 1995 and $60 in 1970, for the same level of housing in constant 2018 dollars. Inflation has been accounted for, so the rises and falls we see in the graph represents changes in the real cost of housing. The ratios hold for any amount, so a monthly housing cost of $1000 in 2018 is equivalent to approximately $700 in 1995 and $600 in 1970—again, in constant 2018 dollars. In summary, we have used the OECD housing index to account for the fluctuations in house prices and we have used the CPI to account for inflation. 4.3.7 Summary of functions introduced Summary of the data preparation functions used in this tutorial, organized by package. dplyr arrange() order the rows of data frame filter() choose rows of a data frame that meet a condition, and omit all others mutate() add new variables (columns) to a data frame select() choose variables (columns) of a data frame and omit all others rename() rename selected variables (columns) of a data frame and keep all others left_join() combine two data frames by variables they have in common rio import() read a data frame by URL or filename export() write a data frame as a specified type of file inspectdf inspect_mem() summarize memory usage of a data frame inspect_na() summarize the rate of missingness of variables in a data frame inspect_ cat() summarize the levels within each categorical variable in a data frame lubridate year() return the year as a number from a date object seplyr group_summarize() perform summary operations on groups defined by selected variables base R head() returns the first part of an R object tail() returns the last part of an R object mean() compute an arithmetic mean round() round to a specified number of decimal places unlist() simplify a list to a vector of values ▲ top of page "]
]
