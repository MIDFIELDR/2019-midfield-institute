[
["index.html", "MIDFIELD Workshops Facilitators Publications Licenses Acknowledgement", " MIDFIELD Workshops The Multiple-Institution Database for Investigating Engineering Longitudinal Development (MIDFIELD) is a partnership of higher education institutions with engineering programs. MIDFIELD contains student record data from 1988–2017 for approximately one million undergraduate, degree-seeking students at the partner institutions. This site provides access to workshop materials for studying how undergraduate students maneuver through their curricula using MIDFIELD data. [For more information about MIDFIELD] Facilitators Matthew Ohland is the MIDFIELD Director and Principal Investigator. He is Professor and Associate Head of Engineering Education at Purdue University. Marisa Orr is the MIDFIELD Associate Director and Assistant Professor in Engineering and Science Education with a joint appointment in Mechanical Engineering at Clemson University. Russell Long is MIDFIELD Managing Director and Data Steward. He developed the stratified data sample for the R packages used in this workshop. Susan Lord is Director of the MIDFIELD Institute and Professor and Chair of Engineering and Professor of Electrical Engineering at the University of San Diego. Richard Layton is the MIDFIELD Director of Data Display and Professor of Mechanical Engineering at Rose-Hulman. He is the lead developer of the R packages used in this workshop. Publications The MIDFIELD team has been exploring and presenting the stories in the MIDFIELD data for several years. To see a sample of our work, you can follow these links: Lord SM, Ohland MW, Layton RA,and Camacho MM (2019) Beyond pipeline and pathways: Ecosystem metrics. Journal of Engineering Education, 108, 32–56, https://doi.org/10.1002/jee.20250 Lord SM, Layton RA, and Ohland MW (2015) Multi-Institution study of student demographics and outcomes in Electrical and Computer Engineering in the USA, IEEE Transactions on Education, 58(3), 141–150, http://dx.doi.org/10.1109/TE.2014.2344622 Brawner CE, Lord SM, Layton RA, Ohland MW, and Long RA (2015) Factors affecting women’s persistence in chemical engineering, International Journal of Engineering Education 31(6A), 1431–1447, https://tinyurl.com/y6jq58xh [For more information about MIDFIELD publications] Licenses The following licenses apply to the text, data, and code in these workshops. Our goal is to minimize legal encumbrances to the dissemination, sharing, use, and re-use of this work. However, the existing rights of authors whose work is cited (text, code, or data) are reserved to those authors. CC-BY 4.0 for all text. GPL-3 for all code. CC0 for all data. Acknowledgement Funding provided by the National Science Foundation Grant 1545667 “Expanding Access to and Participation in the Multiple-Institution Database for Investigating Engineering Longitudinal Development.” "],
["about-the-midfield-workshops.html", "1 About the MIDFIELD workshops 1.1 What is midfieldr? 1.2 Why R? 1.3 Why R graphics?", " 1 About the MIDFIELD workshops 1.1 What is midfieldr? Analytical tools for research in student pathways are generally scarce. The R package midfieldr provides an entry to this type of intersectional research. midfieldr is a R package that provides functions for turning student-record data into persistence metrics. midfielddata is an R package that provides a stratified sample of the MIDFIELD data. This data package contains student records for 98,000 students, suitable for practice with the midfieldr package. [For more information about midfieldr] [For more information about midfielddata] 1.2 Why R? R is an open source language and environment for statistical computing and graphics (R Core Team, 2018), ranked by IEEE in 2018 as the 7th most popular programming language (Python, C++, and Java are the top three) (Cass, 2018). If you are new to R, some of its best features, paraphrasing Wickham (2014), are: R is free, open source, and available on every major platform, making it easy for others to replicate your work. More than 14,250 open-source R packages are available (14,250). Many are cutting-edge tools. R packages provide deep-seated support for data analysis, e.g., missing values, data frames, and subsetting. R packages provide powerful tools for communicating results via html, pdf, docx, or interactive websites. It is easy to get help from experts in the R community. RStudio, an integrated development environment (IDE) for R, includes a console, editor, and tools for plotting, history, debugging, and workspace management as well as access to GitHub for collaboration and version control (RStudio Team, 2016). [For more information about R] [For more information about RStudio] 1.3 Why R graphics? Charles Kostelnick (2007) writes, “The array of design options in software like Microsoft Excel and PowerPoint creates the illusion of flexibility. … So marvelously malleable are these graphical effects—but for whom and to what end? Paradoxically, then, even as the technology for visualizing data has become more sophisticated, it does not necessarily engender rhetorically sensitive design.” The graphics tools in R provide the means to control every pixel in the service of “rhetorically sensitive design.” Designers can craft their visual arguments to balance logos, ethos, pathos, and kairos as appropriate for a given audience in a given rhetorical situation. [For a gallery of R graphics] "],
["midfield-institute-2019.html", "2 MIDFIELD Institute 2019 2.1 Description 2.2 Before you arrive 2.3 Sunday agenda 2.4 Monday agenda 2.5 Tuesday agenda", " 2 MIDFIELD Institute 2019 MIDFIELD Institute June 3–4, 2019 Purdue University, West Lafayette, Indiana, USA Neil Armstrong Hall of Engineering Room B-098 (basement) Contact: Russell Long, ralong@purdue.edu with questions Registration: http://www.conf.purdue.edu/MIDFIELD. 2.1 Description We are offering the first Multiple Institution Database for Investigating Engineering Longitudinal Development (MIDFIELD) Institute on Monday June 3 and Tuesday June 4, 2019 in West Lafayette, Indiana. We welcome faculty, staff, and graduate students. Our learning objectives can be categorized in two broad classes: qualitative and computational. Qualitatively, by the end of the workshop participants should be able to: Describe the data available in MIDFIELD Describe how the MIDFIELD data are organized Describe key principles of effective data visualization Identify deficiencies of common graph types List potential resources beyond MIDFIELD that can contribute to answering research questions Computationally, participants should be able use midfieldr, an R package specifically designed for use with MIDFIELD, to: Calculate and evaluate educational metrics Produce a table of data that addresses a research question Explore and tell a story from MIDFIELD data 2.2 Before you arrive MIDFIELD Workshops for an introduction to MIDFIELD and the workshop facilitators. Getting started for pre-workshop software installation instructions—assuming you plan on using your own laptop. If not, we will have computers available onsite. Optional: For several years now, we have been using R to explore and present the stories in the MIDFIELD data. To see a sample of our data graphics, you can follow the links in the publications section. ▲ top of page 2.3 Sunday agenda 2019-06-02 This is an optional session designed for R novices. Time Activities 4:30–5:30 pm Optional. Time to help anyone needing assistance with the software installation. 5:30–6:00 pm Introductions. Introduce presenters, participants, and learning objectives. Verify that software is installed. 6:00 Pizza should arrive 6:00–6:50 R basics. The RStudio environment and R objects, functions, and scripts 7:00–7:50 Graph basics. Meet ggplot, geom layers, aesthetic mappings, and facets. Writing graphs to file. 8:00–8:50 Data basics. Data import, data structure, and data transformation. Writing data to file. 9:00 Adjourn ▲ top of page 2.4 Monday agenda 2019-06-03 Time Activities 8:00-9:00 Breakfast. Provided in the workshop room. 9:00–10:00 Introductions. Introduce presenters, participants, objectives, MIDFIELD, and persistence metrics we have found insightful. Break 10:15–12:15 Guided practice. Self-paced tutorials using midfieldr and midfielddata. 12:15–1:15 Lunch. Provided in the workshop room. 1:15–2:15 Defining your question. Examples of things to look out for and consider when exploring research questions. Break 2:30–4:30 Self-directed practice. Review the variables in midfielddata. Define a problem involving the data that interests you. Find a collaborator and begin exploring the problem. 4:30–4:45 Conclusion. Reflection and discussion Break 5:00–7:00 Reception. Purdue Union, Anniversary Drawing Room 7:00 Adjourn. Make your own dinner plans. ▲ top of page 2.5 Tuesday agenda 2019-06-04 Time Activities 8:00–9:00 Breakfast. Provided in the workshop room. 9:00–10:00 Data visualization. Deficiencies of common graphs. Creating more effective graphs. Break 10:15–10:45 Explore data. Finding and presenting stories in the data. 10:45–12:15 Self-directed work. Continue the collaborative work from Day 1. Produce data displays that address your research question. 12:15–3:15 Lunch and poster preparation. Lunch provided in the workshop room. Participants make posters to display their work-in-progress. 3:15–4:15 Poster session. 4:15–5:00 Conclusion. Summarize objectives. Plans for proposed 2020 FIE Special Session to showcase participants’ work. Assess MIDFIELD Institute. 5:00 Adjourn ▲ top of page "],
["getting-started.html", "3 Getting started with R 3.1 Install R and RStudio 3.2 Install an R package 3.3 Install midfielddata and midfieldr 3.4 Create an R project 3.5 Create directories", " 3 Getting started with R If you already have R and RStudio installed, please update to the most recent releases and update your R packages as well. If you are joining us for the first time, it is vital that you attempt to set up your computer with the necessary software in advance or it will be difficult to keep up. Unless noted otherwise, we assume the reader is an R novice. Thus the first steps are to install R and RStudio. 3.1 Install R and RStudio Windows users may have to login as an Administrator (localmgr) before installing the software. Install R for your operating system Install RStudio, a user interface for R If you need additional assistance for Mac OS or Linux, these links might be useful Install R and RStudio on Mac OS by Michael Galarnyk (or you can Google more recent instructions) How to Install R Ubuntu 16.04 Xenial by Kris Eberwein (or you can Google more recent instructions) Once the installation is complete, you can take a 2-minute tour of the RStudio interface. Please use headphones or ear-buds if you watch the video during the workshop. Let’s start (00:57–02:32) by R Ladies Sydney (Richmond, 2018) The same video includes a longer (7 minute) tour of the four quadrants (panes) in RStudio if you are interested. The RStudio quadrants (07:21–14:40) by R Ladies Sydney (Richmond, 2018) 3.2 Install an R package The fundamental unit of shareable code in R is the package. For the R novice, an R package is like an “app” for R—a collection of functions, data, and documentation for doing work in R that is easily shared with others (Wickham, 2014). Most packages are obtained from the CRAN website (The Comprehensive R Archive Network). To install a package using RStudio: Launch RStudio The RStudio interface has several panes. We want the Files/Plots/Packages pane. Select the Packages tab Next, Click Install on the ribbon In the dialog box, type tidyverse Check the Install dependencies box Click the Install button Repeat to install the package devtools Alternatively (for future reference), if you prefer using the command-line, you can install a CRAN package (or a vector of packages) by typing install.packages() in the Console, for example, install.packages(pkgs = c(&quot;tidyverse&quot;, &quot;devtools&quot;)) Some packages are archived in a repository other than CRAN, GitHub being a current favorite. For such packages, we use install_github() from the devtools package in this form, devtools::install_github(repo = &quot;user_name/repo_name&quot;) 3.3 Install midfielddata and midfieldr In this workshop, we work with the midfieldr package and midfielddata data-package. The midfielddata package is too large to be stored in CRAN, so we use a special “drat-repository” to make the package source files available. We install these packages by typing lines of code in the Console at the prompt. The Console in the default RStudio pane layout is on the left. The R command prompt in the Console is &gt;. At the prompt, type a line of code and press Enter from your keyboard. Alternatively, you can copy a line of code from this page, paste it in the console, and press Enter. We only run these lines of code once, so you do not have to type the lines into a script. Install midfielddata from the our drat repo. The data package is large so this step takes time. Be patient and wait for the Console prompt &gt; to reappear. install.packages(pkgs = &quot;midfielddata&quot;, repos = &quot;https://MIDFIELDR.github.io/drat/&quot;, type = &quot;source&quot;) In the Console, load the package by typing, library(&quot;midfielddata&quot;) If that installation was successful, only then can you install midfieldr from its GitHub repo, devtools::install_github(repo = &quot;MIDFIELDR/midfieldr&quot;) In the Console, load the package by typing, library(&quot;midfieldr&quot;) If the installation was successful, at the prompt you can type ? midfieldr and see the midfieldr help page in the RStudio Help pane. 3.4 Create an R project To begin any project, we create an RStudio Project file and directory. You can recognize an R project file by its .Rproj suffix. We will create a project named after the workshop, for example, midfield_institute.Rproj, fie_workshop.Rproj, etc. If you prefer your instructions with commentary (please use headphones or ear-buds if you watch the video during the workshop), Start with a Project (02:34–04:50) by R Ladies Sydney (Richmond, 2018) If you prefer basic written instructions, RStudio, File &gt; New Project… &gt; New Directory &gt; New Project Or, click the New Project button in the Console ribbon, In the dialog box that appears, Type the workshop name as the directory name, for example, midfield_institute, fie_workshop, etc. Use the browse button to select a location on your computer to create the project folder Click the Create Project button 3.5 Create directories While file organization is a matter of personal preference, we ask that you use the directory structure shown here for your work in the workshop. Create three folders in the project main directory, where your_project is the name you gave the project, foe example, midfield_institute or fie_workshop. your_project/ ├── data/ ├── figures/ ├── scripts/ └── your_project.Rproj If you prefer your instructions with commentary (please use headphones or ear-buds if you watch the video during the workshop), Make some folders (04:50–06:08) by R Ladies Sydney (Richmond, 2018) If you prefer basic written instructions, use your usual method of creating new folders on your machine or you can use the New Folder button in the Files pane We use the folders as follows: data for data files figures for finished data displays scripts for R scripts that operate on data to produce results And that concludes the setup. "],
["day-0.html", "4 MIDFIELD Pre-Institute Workshop 4.1 R basics 4.2 Graph basics 4.3 Data basics", " 4 MIDFIELD Pre-Institute Workshop Agenda [link] This is an optional session designed for R novices. If you cannot attend this session on Sunday, you are welcome to work these tutorials on your own before the Monday/Tuesday sessions. The tutorials give the R novice a quick introduction to three essential elements of data science using R: R basics Graph basics Data basics The tutorials are designed to be completed by an R novice in less than 50 minutes each. The timing has been student-tested, but of course your mileage may vary. ▲ top of page 4.1 R basics An introduction to R adapted from (Healy, 2019a) with extra material from (Matloff, 2019). If you already have R experience, you might still want to browse this section in case you find something new. If the prerequisites have been met, the tutorial should take no longer than 50 minutes. 4.1.1 Prerequisites Every tutorial assumes that You completed the Getting started instructions You launched midfield_institute.Rproj to start the R session One of the packages is available only on GitHub. To install it, type in the Console, devtools::install_github(&quot;kjhealy/socviz&quot;) Use File &gt; New File &gt; R Script to create a new R script Name the script 01-R-basics.R Save it in the scripts directory Add a minimal header at the top of the script (if you wish) Use library() to load the packages we will use # workshop R basics # name # date library(&quot;tidyverse&quot;) library(&quot;socviz&quot;) Run the script by clicking the Source button. If you see an error like this one, Error in library(&quot;pkg_name&quot;) : there is no package called &#39;pkg_name&#39; then you should install the missing package(s) and run the script again. [To review how to install an R package] Guidelines As you work through the tutorial, type a line or chunk of code then File &gt; Save and Source. Confirm that your result matches the tutorial result. Your turn exercises give you chance to devise your own examples and check them out. You learn by doing (but you knew that already)! 4.1.2 Everything in R has a name In R, every object has a name. named entities, like x or y data you have loaded, like my_data functions you use, like sin() Some names are forbidden reserved words, like TRUE or FALSE programming words, like Inf, for, else, and function special entities, like NA and NaN Some names should not be used because they name commonly used functions q() quit c() combine or concatenate mean() range() var() variance Names in R are case-sensitive my_data and My_Data are different objects I follow the style guide used in the tidyverse by naming things in lower case, with words separated by underscores, and no spaces If you want to know if a name has already been used in a package you have loaded, go to the RStudio console, type a question mark followed by the name, e.g., ? c() ? mean() If the name is in use, a help page appears in the RStudio Help pane. 4.1.3 Everything in R is an object Origins of R objects Some objects are built in to R Some objects are loaded with packages Some objects are created by you Type this line of code in your script, Save, Source. c() is the function to combine or concatenate its elements to create a vector. c(1, 2, 3, 1, 3, 25) In these notes, everything that comes back to us in the Console as the result of running a script is shown prefaced by #&gt;. For example, after running your script, the Console should show, #&gt; [1] 1 2 3 1 3 25 But what is that [1] here? It’s just a row label. We’ll go into that later, not needed yet. We can assign the vector to a name. x &lt;- c(1, 2, 3, 1, 3, 25) y &lt;- c(5, 31, 71, 1, 3, 21, 6) To see the result in the Console, type the object name in the script, Save, and Source. (Remember, type the line of code but not the line prefaced by #&gt;—that’s the output line so you can check your results.) x #&gt; [1] 1 2 3 1 3 25 y #&gt; [1] 5 31 71 1 3 21 6 You create objects my assigning them names &lt;- is the assignment operator (keyboard shortcut: ALT –) objects exist in your R project workspace, listed in the RStudio Environment pane Datasets are also named objects, and a large number of datasets are included in the base R installation. For example,LakeHuron contains annual measurements of the lake level, in feet, from 1875–1972. LakeHuron #&gt; Time Series: #&gt; Start = 1875 #&gt; End = 1972 #&gt; Frequency = 1 #&gt; [1] 580.38 581.86 580.97 580.80 579.79 580.39 580.42 580.82 581.40 581.32 #&gt; [11] 581.44 581.68 581.17 580.53 580.01 579.91 579.14 579.16 579.55 579.67 #&gt; [21] 578.44 578.24 579.10 579.09 579.35 578.82 579.32 579.01 579.00 579.80 #&gt; [31] 579.83 579.72 579.89 580.01 579.37 578.69 578.19 578.67 579.55 578.92 #&gt; [41] 578.09 579.37 580.13 580.14 579.51 579.24 578.66 578.86 578.05 577.79 #&gt; [51] 576.75 576.75 577.82 578.64 580.58 579.48 577.38 576.90 576.94 576.24 #&gt; [61] 576.84 576.85 576.90 577.79 578.18 577.51 577.23 578.42 579.61 579.05 #&gt; [71] 579.26 579.22 579.38 579.10 577.95 578.12 579.75 580.85 580.41 579.96 #&gt; [81] 579.61 578.76 578.18 577.21 577.13 579.10 578.25 577.91 576.89 575.96 #&gt; [91] 576.80 577.68 578.38 578.52 579.74 579.31 579.89 579.96 Now you can see how the row labels work. There are 10 numbers per row, here, so the second row starts with the 11th, indicated by [11]. The last row starts with the 91st value [91] and ends with the 98th value. In the Console, type ? LakeHuron to see the help page for the data set Individual elements of a vector are obtained using [] notation. For example, the first five lake level readings are extracted with LakeHuron[1:5] #&gt; [1] 580.38 581.86 580.97 580.80 579.79 The 4th element alone, LakeHuron[4] #&gt; [1] 580.8 4.1.4 Do things in R using functions Functions do something useful functions are objects the perform actions for you functions produce output based on the input it receives functions are recognized by the parentheses at the end of their names The parentheses are where we include the inputs (arguments) to the function c() concatenates the comma-separated numbers in the parentheses to create a vector mean() computes the mean of a vector of numbers sd() computes the standard deviation of a vector of numbers summary() returns a summary of the object If we try mean() with no inputs, we get an error statement mean() #&gt; Error in mean.default() : argument &quot;x&quot; is missing, with no default If we use the Lake Huron dataset as the argument, the function is computed and displayed. Add these lines to your script, Save, and Source. mean(LakeHuron) #&gt; [1] 579.0041 sd(LakeHuron) #&gt; [1] 1.318299 summary(LakeHuron) #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. #&gt; 576.0 578.1 579.1 579.0 579.9 581.9 We can extract subsets of data using functions. For example, If we wanted only the first five even-numbered elements, we use c() to create a vector of indices to the desired elements, LakeHuron[c(2, 4, 6, 8, 10)] #&gt; [1] 581.86 580.80 580.39 580.82 581.32 If we wanted every 5th entry over the full data set, we use length() to determine how many entries there are, and the sequence function seq() to create the vector of indices, n &lt;- length(LakeHuron) LakeHuron[seq(from = 5, to = n, by = 5)] #&gt; [1] 579.79 581.32 580.01 579.67 579.35 579.80 579.37 578.92 579.51 577.79 #&gt; [11] 580.58 576.24 578.18 579.05 577.95 579.96 577.13 575.96 579.74 Because we will be using the ggplot2 package for graphics, we will not be using the base R plot() function very often, but it is useful for a quick look at data. Add these lines to your script, Save, and Source. plot(LakeHuron) The help pages for functions are quickly accessed via the Console. In the Console type one line at a time and Enter to see the function help page. ? mean() ? sd() ? summary() 4.1.5 R functions come in packages Functions are bundled in packages Families of useful functions are bundled into packages that you can install, load, and use Packages allow you to build on the work of others You can write your own functions and packages too A lot of the work in data science consists of choosing the right functions and giving them the right arguments to get our data into the form we need for analysis or visualization Functions operate on the input you provide and give you back a result. Type the following in your script, Save, and Source. table(x) # table of counts #&gt; x #&gt; 1 2 3 25 #&gt; 2 1 2 1 sd(y) # standard deviation #&gt; [1] 25.14435 x * 5 # multiply every element by a scalar #&gt; [1] 5 10 15 5 15 125 y + 1 # add a scalar to every element #&gt; [1] 6 32 72 2 4 22 7 x + x # add elements #&gt; [1] 2 4 6 2 6 50 Comments are annotations to make the source code easier for humans to understand but are ignored by R. Comments in R are denoted by a hashtag #. 4.1.6 R objects have class Everything is an object and every object has a class. class(x) #&gt; [1] &quot;numeric&quot; class(summary) #&gt; [1] &quot;function&quot; Certain actions will change the class of an object. Suppose we try create a vector from the x object and a text string, new_vector &lt;- c(x, &quot;Apple&quot;) new_vector #&gt; [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;1&quot; &quot;3&quot; &quot;25&quot; &quot;Apple&quot; class(new_vector) #&gt; [1] &quot;character&quot; By adding the word “Apple” to the vector, R changed the class from “numeric” to “character”. All the numbers are enclosed in quotes: they are now character strings and cannot be used in calculations. The most common class of data object we will use is the data frame. titanic # data in the socviz package #&gt; fate sex n percent #&gt; 1 perished male 1364 62.0 #&gt; 2 perished female 126 5.7 #&gt; 3 survived male 367 16.7 #&gt; 4 survived female 344 15.6 class(titanic) #&gt; [1] &quot;data.frame&quot; You can see there are four variables: fate, sex, n, percent. Two variables (columns) are numeric, two are categorical. You can pick variable out of a data frame using the $ operator, titanic$percent #&gt; [1] 62.0 5.7 16.7 15.6 From the tidyverse, we will regularly use a augmented data frame called a tibble. We can convert the titanic data frame to a tibble using as_tibble(). titanic_tb &lt;- as_tibble(titanic) class(titanic_tb) #&gt; [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; titanic_tb #&gt; # A tibble: 4 x 4 #&gt; fate sex n percent #&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 perished male 1364 62 #&gt; 2 perished female 126 5.7 #&gt; 3 survived male 367 16.7 #&gt; 4 survived female 344 15.6 The tibble includes additional information about the variables 4.1.7 R objects have structure To see inside an object ask for its structure using the str() function. str(x) #&gt; num [1:6] 1 2 3 1 3 25 str(titanic) #&gt; &#39;data.frame&#39;: 4 obs. of 4 variables: #&gt; $ fate : Factor w/ 2 levels &quot;perished&quot;,&quot;survived&quot;: 1 1 2 2 #&gt; $ sex : Factor w/ 2 levels &quot;female&quot;,&quot;male&quot;: 2 1 2 1 #&gt; $ n : num 1364 126 367 344 #&gt; $ percent: num 62 5.7 16.7 15.6 str(titanic_tb) #&gt; Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 4 obs. of 4 variables: #&gt; $ fate : Factor w/ 2 levels &quot;perished&quot;,&quot;survived&quot;: 1 1 2 2 #&gt; $ sex : Factor w/ 2 levels &quot;female&quot;,&quot;male&quot;: 2 1 2 1 #&gt; $ n : num 1364 126 367 344 #&gt; $ percent: num 62 5.7 16.7 15.6 I also like to use the glimpse() function from the tidyverse. glimpse(x) #&gt; num [1:6] 1 2 3 1 3 25 glimpse(titanic) #&gt; Observations: 4 #&gt; Variables: 4 #&gt; $ fate &lt;fct&gt; perished, perished, survived, survived #&gt; $ sex &lt;fct&gt; male, female, male, female #&gt; $ n &lt;dbl&gt; 1364, 126, 367, 344 #&gt; $ percent &lt;dbl&gt; 62.0, 5.7, 16.7, 15.6 glimpse(titanic_tb) #&gt; Observations: 4 #&gt; Variables: 4 #&gt; $ fate &lt;fct&gt; perished, perished, survived, survived #&gt; $ sex &lt;fct&gt; male, female, male, female #&gt; $ n &lt;dbl&gt; 1364, 126, 367, 344 #&gt; $ percent &lt;dbl&gt; 62.0, 5.7, 16.7, 15.6 4.1.8 R does what you tell it Expect to make errors and don’t worry when that happens. You won’t break anything. Healy (2019b) offers this advice for three specific things to watch out for: Make sure parentheses are balanced—that every opening ( has a corresponding closing ). Make sure you complete your expressions. If you see a + in the Console instead of the usual prompt &gt;, that means that R thinks you haven’t written a complete expression. You can hit Esc or Ctrl C to force your way back to the Console and try correcting the code. In ggplot specifically, as you will see, we create plots layer by layer, using a + character at the end of the line—not at the beginning of the next line. For example, you would write this, ggplot(data = mpg, aes(x = displ, y = hwy)) + geom_point() not this, # error caused by incorrectly placed + ggplot(data = mpg, aes(x = displ, y = hwy)) + geom_point() To conclude, let’s make bar graph of the titanic data, ggplot(data = titanic_tb, mapping = aes(x = sex, y = n, fill = fate)) + geom_col() + coord_flip() Your turn. As shown, color distinguishes those who survived from those who did not and bar length gives totals by sex. Make a small change so that color denotes sex and bar length gives totals of survived and perished. 4.1.9 Keyboard shortcuts In Windows, Ctrl L clears the Console Alt - creates the assignment operator &lt;- Ctrl Enter runs the selected line(s) of code in an R script Feel free to take a break before starting the next tutorial. ▲ top of page 4.2 Graph basics Decline by Randall Munroe (xkcd.com) is licensed under CC BY-NC 2.5 An introduction to ggplot2 adapted from Chapter 3 from (Healy, 2019b). If you already have R experience, you might still want to browse this section in case you find something new. If the prerequisites have been met, the tutorial should take no longer than 50 minutes. 4.2.1 Prerequisites Every tutorial assumes that You completed the Getting started instructions You launched midfield_institute.Rproj to start the R session Use File &gt; New File &gt; R Script to create a new R script Name the script 02-graph-basics.R Save it in the scripts directory Add a minimal header at the top of the script (if you wish) Use library() to load the packages we will use # workshop graph basics # name # date library(&quot;tidyverse&quot;) library(&quot;gapminder&quot;) Run the script by clicking the Source button. If you see an error like this one, Error in library(&quot;pkg_name&quot;) : there is no package called &#39;pkg_name&#39; then you should install the missing package(s) and run the script again. [To review how to install an R package] Guidelines As you work through the tutorial, type a line or chunk of code then File &gt; Save and Source. Confirm that your result matches the tutorial result. Your turn exercises give you chance to devise your own examples and check them out. You learn by doing (but you knew that already)! 4.2.2 Tidy data If the data set is “tidy”, then every row is an observation and every column is a variable. The gapminder data frame is tidy. We use glimpse() to get a look at the structure. glimpse(gapminder) #&gt; Observations: 1,704 #&gt; Variables: 6 #&gt; $ country &lt;fct&gt; Afghanistan, Afghanistan, Afghanistan, Afghanistan, ... #&gt; $ continent &lt;fct&gt; Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia... #&gt; $ year &lt;int&gt; 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992... #&gt; $ lifeExp &lt;dbl&gt; 28.801, 30.332, 31.997, 34.020, 36.088, 38.438, 39.8... #&gt; $ pop &lt;int&gt; 8425333, 9240934, 10267083, 11537966, 13079460, 1488... #&gt; $ gdpPercap &lt;dbl&gt; 779.4453, 820.8530, 853.1007, 836.1971, 739.9811, 78... And we can just type its name to see the first few rows, gapminder #&gt; # A tibble: 1,704 x 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Afghanistan Asia 1952 28.8 8425333 779. #&gt; 2 Afghanistan Asia 1957 30.3 9240934 821. #&gt; 3 Afghanistan Asia 1962 32.0 10267083 853. #&gt; 4 Afghanistan Asia 1967 34.0 11537966 836. #&gt; 5 Afghanistan Asia 1972 36.1 13079460 740. #&gt; 6 Afghanistan Asia 1977 38.4 14880372 786. #&gt; 7 Afghanistan Asia 1982 39.9 12881816 978. #&gt; 8 Afghanistan Asia 1987 40.8 13867957 852. #&gt; 9 Afghanistan Asia 1992 41.7 16317921 649. #&gt; 10 Afghanistan Asia 1997 41.8 22227415 635. #&gt; # ... with 1,694 more rows Read more about tidy data in (Wickham and Grolemund, 2017). Your turn. The ggplot2 package includes a dataset called mpg. Use glimpse() to examine the data set. How many variables? How many observations? How many of the variables are numeric? How many are character type? Is the data set tidy? Check your work. There are 234 observations and 11 variables. 4.2.3 Anatomy of a graph ggplot() is a our basic plotting function. The data = ... argument assigns the data frame. p &lt;- ggplot(data = gapminder) Next we use the mapping argument mapping = aes(...) to assign variables (column names) from the data frame to specific aesthetic properties of the graph such as the x-coordinate, the y-coordinate color, fill, etc. Here we will map the GDP per capita variable to x and the life expectancy variable to y. p &lt;- ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp)) If we try to print the graph by typing the name of the graph object (everything in R is an object), we get an empty graph because we haven’t told ggplot what sort of a graph we want. p Because the graph will be a scatterplot, we add the geom_point() layer. p &lt;- p +geom_point() p # display the graph In ggplot2, “geoms” are geometric objects such as points, lines, bars, boxplots, contours, polygons, etc. You can browse the full list on the ggplot2 geom reference page. We could also have simply added the layer to the original object, p &lt;- ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp)) + geom_point() p # display the graph Notice that the default axis labels are the variables names from the data frame. We can edit those with another layer p &lt;- p + labs(x = &quot;GDP per capita&quot;, y = &quot;Life expectancy (years)&quot;) p # display the graph Or, with all layers shown in one code chunk, p &lt;- ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp)) + geom_point() + labs(x = &quot;GDP per capita&quot;, y = &quot;Life expectancy (years)&quot;) p # display the graph Summary. The basics steps for building up the layers of any graph consist of, assign the data frame map variables (columns names) to aesthetic properties choose geoms adjust scales, labels, etc. For more information aes() help page geom_point() help page geom_labs() help page Your turn. In the console, type ? mpg to see the data set help page. Skim the descriptions of the variables. Create a scatterplot of highway miles per gallon as a function of engine displacement in liters. Check your work: 4.2.4 Layer: smooth fit Suppose you wanted a smooth fit curve, not necessarily linear. Add a geom_smooth() layer. The name loess (pronounced like the proper name Lois) is a nonparametric curve-fitting method based on local regression. p &lt;- p + geom_smooth(method = &quot;loess&quot;, se = FALSE) p # display the graph The se argument controls whether or not the confidence interval is displayed. Setting se = TRUE yields, p &lt;- p + geom_smooth(method = &quot;loess&quot;, se = TRUE) p # display the graph For a linear-fit layer, we add a layer with method set to lm (short for linear model). The linear fit is not particularly good in this case, but now you know how to do one. p &lt;- p + geom_smooth(method = &quot;lm&quot;, se = TRUE) p # display the graph For more information geom_smooth() help page Your turn. Continue to practice with mpg. Add a loess curve fit with a confidence interval. Check your work: 4.2.5 Layer: log scale We have orders of magnitude differences in the GDP per capita variable. To confirm, we can create a summary() of the gdpPercap variable. The output shows that the minimum is 241, the median 3532, and the maximum 113523. # extract one variable from the data frame this_variable &lt;- gapminder[&quot;gdpPercap&quot;] # statistical summary of one variable summary(this_variable) #&gt; gdpPercap #&gt; Min. : 241.2 #&gt; 1st Qu.: 1202.1 #&gt; Median : 3531.8 #&gt; Mean : 7215.3 #&gt; 3rd Qu.: 9325.5 #&gt; Max. :113523.1 The bracket notation I just used, gapminder[\"gdpPercap\"], is one way to extract a variable from a data frame. In exploring a graph like this, it might be useful to add a layer that changes the horizontal scale to a log-base-10 scale. p &lt;- ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp)) + geom_point() + scale_x_log10() p # display the graph The scales package allows us to change the GDP scale to dollars. Using the syntax thepackage::thefunction we can use the scales::dollar function without loading the scales package. p &lt;- ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp)) + geom_point() + scale_x_log10(labels = scales::dollar) p # display the graph In this case, a linear fit might work, p &lt;- p + geom_smooth(method = &quot;lm&quot;, se = TRUE) p # display the graph Update the axis labels, p &lt;- p + labs(x = &quot;GDP per capita (log10 scale)&quot;, y = &quot;Life expectancy (years)&quot;) p # display the graph In summary, all the layers could have been be coded at once, for example, p &lt;- ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp)) + geom_point() + geom_smooth(method = &quot;lm&quot;, se = TRUE) + scale_x_log10(labels = scales::dollar) + labs(x = &quot;GDP per capita (log10 scale)&quot;, y = &quot;Life expectancy (years)&quot;) With all the layers in one place, we can see that we’ve coded all the basic steps, that is, assign the data frame map variables (columns names) to aesthetic properties choose geoms adjust scales, labels, etc. For more information scale_x_log10() help page Your turn. Continue to practice with mpg. Edit the axis labels to include units. Check your work: 4.2.6 Mapping aesthetics So far, we have mapped variables only to the x-coordinate and y-coordinate aesthetics. If we map a variable to the color aesthetic, the data symbols are automatically assigned different colors and a legend is created. In this example, we map the continent variable to color. p &lt;- ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point() + scale_x_log10(labels = scales::dollar) + labs(x = &quot;GDP per capita&quot;, y = &quot;Life expectancy (years)&quot;) p # print the graph Your turn. Continue to practice with mpg. Map vehicle class to color Change the curve fit to linear Check your work: 4.2.7 Setting properties Because the colors overprint, we might try making the data symbols slightly transparent. In this case, we are not mapping a property to a variable; instead, we want all data symbols to be less opaque. The alpha argument, with \\(0 \\leq \\alpha \\leq 1\\), sets the transparency level. Because this change applies to all data points equally, we assign it in the geom, not aes(). p &lt;- ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp, color = continent)) + geom_point(alpha = 0.3) + scale_x_log10(labels = scales::dollar) + labs(x = &quot;GDP per capita&quot;, y = &quot;Life expectancy (years)&quot;) p # print the graph If we add a linear fit to these data, a fit for each continent is generated. For a thinner line, I’ve added a size argument to the geom. p &lt;- p + geom_smooth(method = &quot;lm&quot;, se = FALSE, size = 0.5) p # print the graph If we want all the data markers the same color but we want to change the color, we don’t map it, we set it in the geom. Here, I’ve omitted the aesthetic mapping to color and used a color assignment in the geom. p &lt;- ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp)) + geom_point(alpha = 0.3, color = &quot;purple1&quot;) + geom_smooth(method = &quot;lm&quot;, se = FALSE, size = 0.5, color = &quot;purple4&quot;) + scale_x_log10(labels = scales::dollar) + labs(x = &quot;GDP per capita (log10 scale)&quot;, y = &quot;Life expectancy (years)&quot;) p # print the graph For more information R color names 4.2.8 Layer: facets In the earlier graph where we mapped continent to color, there was a lot of overprinting, making it difficult to compare the continents. The facet_wrap() layer separates the data into different panels (or facets). Like the aes() mapping, facet_wrap() is applied to a variable (column name) in the data frame. p &lt;- p + facet_wrap(facets = vars(continent)) p # print the graph Comparisons are facilitated by having the facets appear in one column, by using the ncols argument of facet_wrap(). p &lt;- p + facet_wrap(facets = vars(continent), ncol = 1) p # print the graph In a faceted display, all panels have identical scales (the default) to facilitate comparison. Again, all the layers could have been be coded at once, for example, ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp)) + geom_point(alpha = 0.3, color = &quot;purple1&quot;) + geom_smooth(method = &quot;lm&quot;, se = FALSE, size = 0.5, color = &quot;purple4&quot;) + facet_wrap(facets = vars(continent), ncol = 1) + scale_x_log10(labels = scales::dollar) + labs(x = &quot;GDP per capita (log10 scale)&quot;, y = &quot;Life expectancy (years)&quot;) For more information facet_wrap() help page Your turn. Continue to practice with mpg. Map drive type to color Facet on vehicle class Add some transparency to the data symbols Omit the smooth fit Check your work: 4.2.9 Ordering the panels The default ordering of the panels in this example is alphabetical. In most cases, ordering the panels by the data (often the mean or the median) improves the display. Here we have two quantitative variables, but the one that is the more interesting is life expectancy. Our goal then is to order the continent variable by the median of the lifeExp variable in each panel. To do that, we require continent to be a factor, a type of variable specialized for creating ordered levels of a category. Using glimpse() we see that continent is already a factor (&lt;fct&gt;). glimpse(gapminder) #&gt; Observations: 1,704 #&gt; Variables: 6 #&gt; $ country &lt;fct&gt; Afghanistan, Afghanistan, Afghanistan, Afghanistan, ... #&gt; $ continent &lt;fct&gt; Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia... #&gt; $ year &lt;int&gt; 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992... #&gt; $ lifeExp &lt;dbl&gt; 28.801, 30.332, 31.997, 34.020, 36.088, 38.438, 39.8... #&gt; $ pop &lt;int&gt; 8425333, 9240934, 10267083, 11537966, 13079460, 1488... #&gt; $ gdpPercap &lt;dbl&gt; 779.4453, 820.8530, 853.1007, 836.1971, 739.9811, 78... Therefore all we have to do is tell R that we want the levels of continent ordered by the median of life expectancy using the fct_reorder() function. gapminder &lt;- gapminder %&gt;% mutate(continent = fct_reorder(continent, lifeExp, median)) In doing so, I’ve overwritten the original gapminder dataset with my revised version. We set the as.table argument to false to place the panel with the highest life expectancy in the top position. ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp)) + geom_point(alpha = 0.3, color = &quot;purple1&quot;) + geom_smooth(method = &quot;lm&quot;, se = FALSE, size = 0.5, color = &quot;purple4&quot;) + facet_wrap(facets = vars(continent), ncol = 1, as.table = FALSE) + scale_x_log10(labels = scales::dollar) + labs(x = &quot;GDP per capita (log10 scale)&quot;, y = &quot;Life expectancy (years)&quot;) For more information mutate() help page fct_reorder() help page Your turn. Continue to practice with mpg. Convert class to a factor ordered by the mean highway mileage Same graph as before, but order the panels by mean fuel consumption Check your work: 4.2.10 Beyond the basics Demonstrating how the basics can be built upon to create a complex data graphic. To wrap up this introduction, I’ll show you how we can use functions in various layers to show all the data in every panel; add a common overall loess smooth fit; and highlight the the continent data in each panel, making it easier to compare each continent to the global data. Because life expectancy has generally increased over time, I’m going to restrict this final graph to 2007, the most recent year in this dataset. Typing this code in your script is optional. Without further explanation, here’s the code. gapminder &lt;- gapminder %&gt;% filter(year == 2007) ggplot(data = gapminder, mapping = aes(x = gdpPercap / 1000, y = lifeExp)) + geom_point(data = select(gapminder, -continent), size = 1.25, alpha = 0.5, color = &quot;#80cdc1&quot;) + geom_smooth(data = select(gapminder, -continent), method = &quot;loess&quot;, se = FALSE, size = 0.7, color = &quot;#80cdc1&quot;) + geom_point(mapping = aes(color = continent), size = 1.25, color = &quot;#01665e&quot;) + facet_wrap(vars(continent), ncol = 1, as.table = FALSE) + labs(x = &quot;GDP per capita (thousands of dollars)&quot;, y = &quot;Life expectancy (years)&quot;, title = &quot;Life expectancy by country, 2007&quot;, caption = &quot;Source: Gapminder&quot;) + theme(legend.position = &quot;none&quot;) For more information select() help page filter() help page theme() help page ColorBrewer for color hex codes 4.2.11 Resize and write to file For consistent control over the size and aspect ratio of your publication-ready graph, you should always conclude your design by saving the image and sizing it at the same time. Here, we save the figure to the figures directory we set up earlier. ggsave(filename = &quot;figures/02-graph-basics-gapminder.png&quot;, width = 6.5, height = 10.5, units = &quot;in&quot;, dpi = 300) And the final figure looks like this: For more information ggsave() help page Your turn. Continue to practice with mpg. Write your ggsave() code chunk immediately following the ggplot() code chunk of the graph you want to save. Use ggsave to write your graph to the figures directory with the name 02-graph-basics-mpg.png Try a 6 in by 6 in figure size Check your work: Navigate to your figures folder. The new png file should be there. Open it to confirm it is the figure you expect. Feel free to take a break before starting the next tutorial. ▲ top of page 4.3 Data basics In Tidy Data, Hadley Wickham says, It is often said that 80% of data analysis is spent on the process of cleaning and preparing the data. Data preparation is not just a first step, but must be repeated many times over the course of analysis as new problems come to light or new data is collected. The goal of this 50-minute tutorial is to introduce three basic steps of data preparation: Step 1. Importing raw data and writing to file. Step 2. Identifying the data structure. Step 3. Transforming, reshaping, and joining. 4.3.1 Prerequisites Every tutorial assumes that You completed the Getting started instructions You launched midfield_institute.Rproj to start the R session Install the inspectdf package from GitHub. If a message comes up about updating packages, you can type the number that corresponds to None for now. devtools::install_github(&quot;alastairrushworth/inspectdf&quot;) Use File &gt; New File &gt; R Script to create a new R script Name the script 03-data-basics.R Save it in the scripts directory Add a minimal header at the top of the script (if you wish) Use library() to load the packages we will use # workshop data basics # name # date library(&quot;tidyverse&quot;) library(&quot;lubridate&quot;) library(&quot;seplyr&quot;) library(&quot;rio&quot;) library(&quot;inspectdf&quot;) Run the script by clicking the Source button. If you see an error like this one, Error in library(&quot;pkg_name&quot;) : there is no package called &#39;pkg_name&#39; then you should install the missing package(s) and run the script again. [To review how to install an R package] Guidelines As you work through the tutorial, type a line or chunk of code then File &gt; Save and Source. Confirm that your result matches the tutorial result. Your turn exercises give you chance to devise your own examples and check them out. You learn by doing (but you knew that already)! 4.3.2 Data sets in R Practice data sets are included with the basic R installation and with some R packages. To list the practice data sets available in R, type in the Console, # type in the Console data() which yields #&gt; AirPassengers Monthly Airline Passenger Numbers #&gt; BJsales Sales Data with Leading Indicator #&gt; BOD Biochemical Oxygen Demand #&gt; CO2 Carbon Dioxide Uptake in Grass Plants #&gt; Formaldehyde Determination of Formaldehyde etc. We use the data() function to list practice datasets included in a package (if any). For example, to determine what packages are bundled with the dplyr package, type in the Console, # type in the Console data(package = &quot;dplyr&quot;) yields #&gt; band_instruments Band membership #&gt; band_instruments2 Band membership #&gt; band_members Band membership #&gt; nasa NASA spatio-temporal data #&gt; starwars Starwars characters #&gt; storms Storm tracks data Every data set in base R and in R packages has a help page that describes the data format and variable names. The data help page can be accessed using help(), for example, # type in the Console help(starwars, package = &quot;dplyr&quot;) Alternatively, if the package is loaded, you may run the ? item-name syntax in the Console, # type in the Console library(&quot;dplyr&quot;) ? starwars yields Your turn. These exercises assume that you have successfully followed the instructions to install midfielddata and midfieldr. Determine the names of the datasets available in the midfieldr package. Check your work Determine the variables in case_stickiness (one of the datasets in the midfieldr package). Check your work Determine the names of the datasets available in the midfielddata package. Check your work Determine the variables in midfielddegrees (one of the datasets in the midfielddata package). Check your work 4.3.3 Data structure When we first encounter any data set, the first step is to characterize its structure including, the R data structure, e.g., vector, matrix, data frame, time series, list, etc. the number of observations the number of variables the name and class of each variable We use these functions—encountered in R basics—to examine the structure of a dataset. . str() glimpse() class() [To read more about R data structures] 4.3.4 Example: Create a 2018 price index In this example, we obtain historical Consumer Price Index data from the Federal Reserve (FRED) and perform the necessary data carpentry to graph a price index with respect to 2018 dollars. Over any time period with inflation, a dollar buys less at the end the period than it did at the beginning of the period. Thus, in 1973 a single 20-year old could live comfortably on $5/hour but in 2018 (45 years later) a 20-year-old has to earn $30/hour to achieve the same modest standard of living. We usually adjust for the effects of inflation in US dollars using the Consumer Price Index (CPI) published by the US Bureau of Labor Statistics (BLS). The CPI is available by month from the BLS or from the Federal Reserve (FRED), from 1913 to the present. Step 1. Importing raw data and writing to file. The URL to obtain the CPI data from the FRED is http://research.stlouisfed.org/fred2/data/CPIAUCNS.txt. If you click on the link, you can see that the data starts on line 14; the first 13 lines of the text are meta-information: Title: Consumer Price Index for All Urban Consumers: All Items Series ID: CPIAUCNS Source: U.S. Bureau of Labor Statistics Release: Consumer Price Index Seasonal Adjustment: Not Seasonally Adjusted Frequency: Monthly Units: Index 1982-1984=100 Date Range: 1913-01-01 to 2019-04-01 Last Updated: 2019-05-10 7:42 AM CDT Notes: Handbook of Methods - (https://www.bls.gov/opub/hom/pdf/cpihom.pdf) Understanding the CPI: Frequently Asked Questions - (https://www.bls.gov/cpi/questions-and-answers.htm) Assign the URL url &lt;- &quot;http://research.stlouisfed.org/fred2/data/CPIAUCNS.txt&quot; Import the data using rio::import(), skipping the first 13 lines x &lt;- rio::import(url, skip = 13) Convert the txt file to CSV and write to file in our data directory rio::export(x, &quot;data/cpi-raw.csv&quot;) Now that we have imported the data and written it to file, we don’t have to re-import the data from the Internet every time we Source this R script. We can comment-out those lines as follows (the hashtag # indicates an R comment, that is, a non-executable line of code). # url &lt;- &quot;http://research.stlouisfed.org/fred2/data/CPIAUCNS.txt&quot; # x &lt;- rio::import(url, skip = 13) # rio::export(x, &quot;data/cpi-raw.csv&quot;) Once you have obtained your raw data, save it to file (like we did above) and leave that file unaltered. Never manipulate that data file manually; such operations waste time and are error-prone. Instead, to support the reproducibilty of your work, do all your data preparation in a scripted environment with explicit links to data files. Step 2. Identifying the data structure. Read the data into R using read_csv(). cpi &lt;- read_csv(&quot;data/cpi-raw.csv&quot;) Use class() to determine that the cpi data object itself has the structure of a tibble (a type of data frame). class(cpi) #&gt; [1] &quot;spec_tbl_df&quot; &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; Use glimpse() to examine the data object, which tells us we have 1276 observations of 2 variables: {DATE, VALUE} glimpse(cpi) #&gt; Observations: 1,276 #&gt; Variables: 2 #&gt; $ DATE &lt;date&gt; 1913-01-01, 1913-02-01, 1913-03-01, 1913-04-01, 1913-05... #&gt; $ VALUE &lt;dbl&gt; 9.8, 9.8, 9.8, 9.8, 9.7, 9.8, 9.9, 9.9, 10.0, 10.0, 10.1... The first few values of the date variable tell us that these are monthly data. VALUE is the monthly CPI. This agrees with the metadata above that gave us a date range of 1913-01-01 to 2019-04-01 which is 106 years + 4 months = 1276 months (observations) total. The glimpse() also tells us that DATE is of the date class VALUE is a double precision floating point number We use functions from the inspectdf package to tell us more about the data frame. library(&quot;inspectdf&quot;) x &lt;- cpi inspect_types() confirms the number and type of variables inspect_types(x) # variable type #&gt; # A tibble: 2 x 4 #&gt; type cnt pcnt col_name #&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;list&gt; #&gt; 1 Date 1 50 &lt;chr [1]&gt; #&gt; 2 numeric 1 50 &lt;chr [1]&gt; inspect_mem() indicates the amount of memory each variable requires inspect_mem(x) # memory #&gt; # A tibble: 2 x 3 #&gt; col_name size pcnt #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 DATE 10.23 Kb 50.5 #&gt; 2 VALUE 10.02 Kb 49.5 inspect_na() indicates that there are no missing values inspect_na(x) # NAs #&gt; # A tibble: 2 x 3 #&gt; col_name cnt pcnt #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 DATE 0 0 #&gt; 2 VALUE 0 0 inspect_num() summarizes the numerical variables, in this case, the CPI inspect_num(x) # numeric variables #&gt; # A tibble: 1 x 10 #&gt; col_name min q1 median mean q3 max sd pcnt_na hist #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;list&gt; #&gt; 1 VALUE 9.7 17.4 32.0 78.9 141. 256. 76.9 0 &lt;tibble [28 ~ inspect_cat() summarizes the categorical variables, in this case, the date inspect_cat(x) # categorical variables #&gt; # A tibble: 1 x 5 #&gt; col_name cnt common common_pcnt levels #&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;list&gt; #&gt; 1 DATE 1276 1913-01-01 0.0784 &lt;tibble [1,276 x 3]&gt; inspect_cat() provides correlation coefficients (if any) inspect_cor(x) # correlation (if any) #&gt; # A tibble: 0 x 3 #&gt; # ... with 3 variables: col_1 &lt;chr&gt;, col_2 &lt;chr&gt;, corr &lt;dbl&gt; These data are in what Hadley Wickham calls “tidy” form, that is, Each variable is in a column Each observation is a row Each value is a cell Such an organization is also called a “data matrix” or a “de-normalized form” (Mount, 2019). Your turn. Use the inspectdf functions on midfielddata::midfielddegrees Check your work: #&gt; # A tibble: 2 x 4 #&gt; type cnt pcnt col_name #&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;list&gt; #&gt; 1 character 4 80 &lt;chr [4]&gt; #&gt; 2 numeric 1 20 &lt;chr [1]&gt; #&gt; # A tibble: 5 x 3 #&gt; col_name size pcnt #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 id 6.7 Mb 69.1 #&gt; 2 cip6 780.14 Kb 7.85 #&gt; 3 degree 763.66 Kb 7.69 #&gt; 4 institution 763.61 Kb 7.69 #&gt; 5 term_degree 762.86 Kb 7.68 #&gt; # A tibble: 5 x 3 #&gt; col_name cnt pcnt #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 cip6 50141 51.4 #&gt; 2 term_degree 50141 51.4 #&gt; 3 degree 50141 51.4 #&gt; 4 id 0 0 #&gt; 5 institution 0 0 Step 3. Transforming, reshaping, and joining. Change the column names cpi &lt;- cpi %&gt;% dplyr::rename(date = DATE, cpi = VALUE) %&gt;% glimpse() #&gt; Observations: 1,276 #&gt; Variables: 2 #&gt; $ date &lt;date&gt; 1913-01-01, 1913-02-01, 1913-03-01, 1913-04-01, 1913-05-... #&gt; $ cpi &lt;dbl&gt; 9.8, 9.8, 9.8, 9.8, 9.7, 9.8, 9.9, 9.9, 10.0, 10.0, 10.1,... Convert the date to a date variable and extract the year cpi &lt;- cpi %&gt;% mutate(date = lubridate::ymd(date)) %&gt;% mutate(year = lubridate::year(date)) %&gt;% glimpse() #&gt; Observations: 1,276 #&gt; Variables: 3 #&gt; $ date &lt;date&gt; 1913-01-01, 1913-02-01, 1913-03-01, 1913-04-01, 1913-05-... #&gt; $ cpi &lt;dbl&gt; 9.8, 9.8, 9.8, 9.8, 9.7, 9.8, 9.9, 9.9, 10.0, 10.0, 10.1,... #&gt; $ year &lt;dbl&gt; 1913, 1913, 1913, 1913, 1913, 1913, 1913, 1913, 1913, 191... Omit 2019 data because we don’t have a full year Group and summarize by year to determine the annual CPI (this assumes our data we wish to adjust is annual data) cpi &lt;- cpi %&gt;% filter(year != 2019) %&gt;% seplyr::group_summarise(., &quot;year&quot;, cpi = mean(cpi)) %&gt;% mutate(cpi = round(cpi, 2)) %&gt;% glimpse() #&gt; Observations: 106 #&gt; Variables: 2 #&gt; $ year &lt;dbl&gt; 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 192... #&gt; $ cpi &lt;dbl&gt; 9.88, 10.02, 10.11, 10.88, 12.82, 15.04, 17.33, 20.04, 17... To see what the CPI numbers look like, we can graph it. p &lt;- ggplot(data = cpi, mapping = aes(x = year, y = cpi)) + geom_line() p The basis year is the year for which the CPI = 100. In this data, the basis year is 1983-1984. df_note &lt;- cpi %&gt;% filter(near(cpi, 100, tol = 0.5)) p &lt;- p + geom_point(data = df_note, aes(x = year, y = cpi), size = 2, color = &quot;red&quot;) p ▲ top of page "],
["day-1.html", "5 MIDFIELD Institute Day 1 Prerequisites", " 5 MIDFIELD Institute Day 1 Agenda [link] Prerequisites We assume you have completed all of the Getting started instructions. Run midfield_institute.Rproj to start every work session "],
["day-2.html", "6 MIDFIELD Institute Day 2 Prerequisites", " 6 MIDFIELD Institute Day 2 Agenda [link] Prerequisites We assume you have completed all of the Getting started instructions. Run midfield_institute.Rproj to start every work session "],
["references.html", "References", " References Cass S (2018) The 2018 top programming languages. IEEE Spectrum https://tinyurl.com/ya9nbejt Healy K (2019a) Get Started. Data Visualization: A Practical Introduction. Princeton University Press, Princeton, NJ, 32–53 Healy K (2019b) Data Visualization: A Practical Introduction. Princeton University Press, Princeton, NJ https://kieranhealy.org/publications/dataviz/ Kostelnick C (2007) The visual rhetoric of data displays: The conundrum of clarity. IEEE Transactions on Professional Communication 50(2), 280–294 Matloff N (2019) fasteR: Fast Lane to Learning R! https://github.com/matloff/fasteR Mount J (2019) What is \"Tidy Data\"? Win Vector LLC http://www.win-vector.com/blog/2019/05/what-is-tidy-data/ R Core Team (2018) R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria https://www.R-project.org/ Richmond J (2018) Basic Basics Lesson 1: An opinionated tour of RStudio. https://youtu.be/kfcX5DEMAp4 RStudio Team (2016) RStudio: Integrated Development Environment for R. RStudio, Inc., Boston, MA http://www.rstudio.com/ The Comprehensive R Archive Network https://cran.r-project.org/ Wickham H (2014) Advanced R. Taylor &amp; Francis Wickham H and Grolemund G (2017) R for Data Science. O’Reilly Media, Inc., Sebastopol, CA https://r4ds.had.co.nz/ "]
]
